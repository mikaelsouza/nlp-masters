{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudo de Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentenças Fictícias:\n",
    "\n",
    "- o mikas ta ali\n",
    "- eu gosto de batata frita\n",
    "- existem elefantes\n",
    "\n",
    "Informações\n",
    "- O tamanho da maior sentença é 5.\n",
    "- Temos 3 exemplos de teste.\n",
    "- Usaremos inteiros para representar cada palavra.\n",
    "- Usaremos 0 para representar os espaços vazios das sentenças.\n",
    "- O tamanho do nosso vocabulário é 12 pois temos 12 palavras distintas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Temos 3 sentenças e a maior sentença tem 5 tokens.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 5])"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "sentence_matrix = torch.LongTensor([\n",
    "    [1,   2,  3,  4, 0], #       o     mikas   ta      ali\n",
    "    [5,   6,  7,  8, 9], #      eu     gosto   de   batata   frita\n",
    "    [10, 11,  0,  0, 0], # existem elefantes\n",
    "\n",
    "])\n",
    "qnt_sentences, max_sentence_len = sentence_matrix.shape\n",
    "print(f\"Temos {qnt_sentences} sentenças e a maior sentença tem {max_sentence_len} tokens.\")\n",
    "sentence_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em geral não usamos representações inteiras para representar palavras, mas sim embedding.\n",
    "\n",
    "Geraremos embeddings fictícios de tamanho 10 para os 12 tokens disponíveis no vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Temos 5 embeddings de tamanho 10.\n"
    }
   ],
   "source": [
    "vocab_size = len(sentence_matrix.unique())\n",
    "embedding_size = 10\n",
    "embeddings = np.random.random((vocab_size, embedding_size))\n",
    "# Convertendo para tensor:\n",
    "embeddings = torch.Tensor(embeddings)\n",
    "print(f\"Temos {max_sentence_len} embeddings de tamanho {embedding_size}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora geraremos a matriz de input para os modelos.\n",
    "\n",
    "- Nela teremos o shape 3, 5, 10 que representam as 3 sentenças com no máximo 5 tokens.\n",
    "- Cada token é representado por um embedding de tamanho 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Temos 3 instancias de no máximo 5 tokens representados por embeddings de tamanho 10.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 5, 10])"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "indexes = sentence_matrix\n",
    "input_matrix = embeddings[indexes]\n",
    "print(\"Temos {0} instancias de no máximo {1} tokens representados por embeddings de tamanho {2}.\".format(*input_matrix.shape))\n",
    "input_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passando inputs pela camada de RNN:\n",
    "\n",
    "A atenção é gerada a partir dos outputs gerados pela camada da RNN, portanto passaremos o input pela camada de RNN:\n",
    "\n",
    "A nova saída da RNN vai ter shape (3, 5, 100) onde 3 é o número de batches, 5 é o tamanho máximo da sequência e 4 é o tamanho da representação gerada pela RNN (hidden_size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Temos 3 inputs de tamanho máximo 5 representado por 4 dimensões.\n"
    }
   ],
   "source": [
    "rnn = torch.nn.RNN(input_size=embedding_size, hidden_size=4, batch_first=True)\n",
    "output, _ = rnn(input_matrix)\n",
    "print(\"Temos {0} inputs de tamanho máximo {1} representado por {2} dimensões.\".format(*output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 5, 4])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(4, 5, bias=False)\n",
    "linear_output = linear(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([3, 5, 5])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[ 0.4493, -0.8465, -0.4649, -0.7994,  0.2040],\n         [ 0.3613, -0.8698, -0.4298, -0.7632,  0.2384],\n         [ 0.2638, -0.8425, -0.3597, -0.6367,  0.2164],\n         [ 0.1620, -0.6044, -0.3500, -0.5218,  0.3112],\n         [ 0.3678, -0.9263, -0.4137, -0.7505,  0.1974]],\n\n        [[ 0.5426, -1.0014, -0.4813, -0.8695,  0.1229],\n         [ 0.2917, -0.7588, -0.4266, -0.6434,  0.2789],\n         [ 0.0886, -0.6661, -0.3225, -0.5285,  0.3490],\n         [ 0.4143, -0.7720, -0.5061, -0.6674,  0.2437],\n         [ 0.1935, -0.5650, -0.4226, -0.4285,  0.3245]],\n\n        [[ 0.3615, -0.7878, -0.4019, -0.5959,  0.1527],\n         [ 0.2628, -0.6280, -0.4005, -0.5332,  0.2600],\n         [ 0.3425, -0.9095, -0.4020, -0.7436,  0.2118],\n         [ 0.4627, -0.9608, -0.4652, -0.8581,  0.1925],\n         [ 0.4504, -0.9553, -0.4612, -0.8542,  0.2005]]],\n       grad_fn=<UnsafeViewBackward>)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "print(linear_output.shape)\n",
    "linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[0.3644, 0.0997, 0.1461, 0.1046, 0.2852],\n         [0.3385, 0.0988, 0.1534, 0.1099, 0.2993],\n         [0.3099, 0.1025, 0.1661, 0.1259, 0.2955],\n         [0.2681, 0.1246, 0.1607, 0.1353, 0.3113],\n         [0.3446, 0.0945, 0.1577, 0.1126, 0.2906]],\n\n        [[0.4043, 0.0863, 0.1452, 0.0985, 0.2657],\n         [0.3108, 0.1087, 0.1516, 0.1220, 0.3069],\n         [0.2519, 0.1184, 0.1670, 0.1359, 0.3268],\n         [0.3465, 0.1058, 0.1380, 0.1175, 0.2922],\n         [0.2714, 0.1271, 0.1465, 0.1457, 0.3093]],\n\n        [[0.3358, 0.1064, 0.1565, 0.1289, 0.2725],\n         [0.2964, 0.1216, 0.1527, 0.1337, 0.2956],\n         [0.3360, 0.0961, 0.1596, 0.1134, 0.2949],\n         [0.3750, 0.0903, 0.1483, 0.1001, 0.2862],\n         [0.3708, 0.0909, 0.1490, 0.1006, 0.2888]]], grad_fn=<SoftmaxBackward>)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "torch.nn.functional.softmax(linear_output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitgeneralvenvc4cf915d2c6c41e5adbfa847c95cabc9",
   "display_name": "Python 3.8.2 64-bit ('general': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}