{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp, transformers, torch, tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\nEpoch: 0, Loss: 10.76230525970459\nEpoch: 1, Loss: 10.030280113220215\nEpoch: 2, Loss: 9.497891426086426\nEpoch: 3, Loss: 8.852696418762207\nEpoch: 4, Loss: 8.497407913208008\nEpoch: 5, Loss: 8.063995361328125\nEpoch: 6, Loss: 7.533941268920898\nEpoch: 7, Loss: 7.111499786376953\nEpoch: 8, Loss: 6.74473237991333\nEpoch: 9, Loss: 6.354745388031006\nExamples: \n <s><s><s>Resumption of the session. Resumption of of the the session of the House of Representatives. Resuming of the Senate session. resuming the session the Senate resumed of the chamber. resumption the session resumed the session and resumed the the House session.Resumption the the</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\nEpoch: 10, Loss: 6.047837734222412\nEpoch: 11, Loss: 5.854670524597168\nEpoch: 12, Loss: 5.5716400146484375\nEpoch: 13, Loss: 5.460593223571777\nEpoch: 14, Loss: 5.1479058265686035\nEpoch: 15, Loss: 4.955032825469971\nEpoch: 16, Loss: 4.727998733520508\nEpoch: 17, Loss: 4.476855754852295\nEpoch: 18, Loss: 4.1812744140625\nEpoch: 19, Loss: 3.961792469024658\nExamples: \n <s><s><s>Resumption of of the of the session session session resumed resumed resumed of of of session session resume resumed resumed session resumed session resume session session resumes session session started session session began session session start session session ended session session. session session sessions session sessions sessions session sessionSession session session</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\nEpoch: 20, Loss: 3.6948928833007812\nEpoch: 21, Loss: 3.460512399673462\nEpoch: 22, Loss: 3.119737148284912\nEpoch: 23, Loss: 2.867365837097168\nEpoch: 24, Loss: 2.6333963871002197\nEpoch: 25, Loss: 2.4579079151153564\nEpoch: 26, Loss: 2.2404401302337646\nEpoch: 27, Loss: 1.990664005279541\nEpoch: 28, Loss: 1.8137403726577759\nEpoch: 29, Loss: 1.6427313089370728\nExamples: \n <s><s><s>Resumption of of of the the of the of of session session session sessions session sessionSession session sessions sessions session sessionsSession sessions sessions sessionsSessionSessionSession sessions sessionSession sessionsSession sessionSessionSession session session recessSessionSession recess recess recessRegardless RegardlessRegardlessRegardlessRegardless Regardless Regardless RegardlessRegardless Regardless regardlessRegardless Regardless irrespective Regardless Regardless regardless Regardless Regardless irrespectiveRegardless Regardless Hemisphere Regardless Regardless Hancock Regardless Regardless HemisphereRegardless Regardless Hancock Hancock Hancock Hemisphere Hemisphere RegardlessRegardless Hemisphere Hemisphere HemisphereRegardless Hemisphere Regardless Hemisphere Hemisphere Host Hemisphere Hemisphere Despite Hemisphere Hemisphere)... Hemisphere Hemisphere hemisphere Hemisphere Hemisphere Continent Hemisphere Hemisphere Americas Hemisphere Hemisphere)] Hemisphere Hemisphere  Hemisphere Hemisphere Chin Hemisphere Hemisphere)]. Hemisphere Hemisphere Havana Hemisphere Hemisphere...\" Hemisphere Hemisphere..... Hemisphere Hemisphereén Hemisphere Hemisphere.... Hemisphere Hemisphere,...</s>\nEpoch: 30, Loss: 1.5058398246765137\nEpoch: 31, Loss: 1.4135361909866333\nEpoch: 32, Loss: 1.3062617778778076\nEpoch: 33, Loss: 1.2163136005401611\nEpoch: 34, Loss: 1.1070091724395752\nEpoch: 35, Loss: 1.071674108505249\nEpoch: 36, Loss: 0.9438119530677795\nEpoch: 37, Loss: 0.8924301862716675\nEpoch: 38, Loss: 0.8408543467521667\nEpoch: 39, Loss: 0.7629018425941467\nExamples: \n <s><s>Resumption of of of the of the the session session sessionSession session session sessions session session recess recess recessRegardlessRegardlessRegardless RegardlessRegardless Regardless Regardless RegardlessRegardlessRegardless Hancock Regardless Regardless Hancock RegardlessRegardless Hancock Hancock Regardless Hancock Hancockancock Hancock Hancock Hancock Hemisphere Hancock Hancock Hassan Hancock HancockRegardlessRegardless Hemisphere Hancock Hemisphere Hemisphere Hemisphere hemisphere hemisphere Hemisphere hemisphere Hemisphere Hemisphere Americas Hemisphere Hemisphere Regardless Regardless Hemisphere Hemisphere Havana Hemisphere Hemisphere)... Hemisphere Hemisphere Cuban Hemisphere Hemisphere...\" Hemisphere Hemisphere (). Hemisphere Hemisphere 1024 Hemisphere Hemisphere 698 Hemisphere Hemisphereaci Hemisphere Hemisphereocal Hemisphere HemisphereCarl Hemisphere HemisphereRegardless Hemisphere Hemisphereaca Hemisphere Hemisphere)] Hemisphere HemisphereHispanic Hemisphere Hemisphereimen Hemisphere Hemisphereican Hemisphere Hemispherecenter Hemisphere HemisphereComm Hemisphere Hemisphere)]. Hemisphere Hemisphere508 Hemisphere HemisphereEach Hemisphere HemisphereCub Hemisphere HemisphereEn\nEpoch: 40, Loss: 0.7207733988761902\nEpoch: 41, Loss: 0.690335750579834\nEpoch: 42, Loss: 0.6441264152526855\nEpoch: 43, Loss: 0.6091470122337341\nEpoch: 44, Loss: 0.5607258081436157\nEpoch: 45, Loss: 0.5746996998786926\nEpoch: 46, Loss: 0.5049030780792236\nEpoch: 47, Loss: 0.47524675726890564\nEpoch: 48, Loss: 0.45091789960861206\nEpoch: 49, Loss: 0.4185599982738495\nExamples: \n <s><s><s>Resumption of of of the of the session session sessionSession session session sessions session session suspension suspension suspensionstastastaststaststststSTSTSTstSTstStstSTStStStstStStSTSTStststStSTststKatstStKatstKatStKatKatKat KatKatKatIntKatKatAttAttKatKat)\"KatKatinkKatKat317KatKatKKatKat),\"KatKatAKKatKat...\"KatKat\"...KatKatInKatKat)...KatKatkatKatKatakKatKatcatKatKatockKatKatCatKatKatPinkKatKatCKatKatBarKatKatConfKatKatitKatKatickKatKatItKat\nEpoch: 50, Loss: 0.4275575280189514\nEpoch: 51, Loss: 0.4112020432949066\nEpoch: 52, Loss: 0.3802545368671417\nEpoch: 53, Loss: 0.35662513971328735\nEpoch: 54, Loss: 0.3497768044471741\nEpoch: 55, Loss: 0.34072643518447876\nEpoch: 56, Loss: 0.31589362025260925\nEpoch: 57, Loss: 0.31009000539779663\nEpoch: 58, Loss: 0.30378472805023193\nEpoch: 59, Loss: 0.2901996970176697\nExamples: \n <s><s><s>Resumptionumption resumedumptionumptionumption suspension suspension suspension suspended suspension suspensionsusp Susp Susp Suspsusp Suspsuspsusp Suspst SuspstspstststStStStststSTstStstStSTststestststistststastststinkstststatststattststitststKatKatKatStKatKatstKatstStKatststIntKatKatastKatKatAttKatKat...\"KatKat KatKatKatInKatKat)\"KatKatinkKatKat317KatKatcatKatKatKKatKatockKatKatakKatKatitKatKat)...KatKatickKatKat\"...KatKatChristKatKat),\"KatKatAKKatKatIntKat\nEpoch: 60, Loss: 0.27716946601867676\nEpoch: 61, Loss: 0.2728046178817749\nEpoch: 62, Loss: 0.2679150402545929\nEpoch: 63, Loss: 0.258694589138031\nEpoch: 64, Loss: 0.24821710586547852\nEpoch: 65, Loss: 0.24749025702476501\nEpoch: 66, Loss: 0.2389809489250183\nEpoch: 67, Loss: 0.23330245912075043\nEpoch: 68, Loss: 0.22543761134147644\nEpoch: 69, Loss: 0.22513574361801147\nExamples: \n <s><s><s>The the the the The The The the The the theThe the TheTheTheThe theTheThetheTheTheDespite the theDespite theTheIn the the...TheThe)...TheThe,...TheThe...The...\"The...\"Despite the...\"...\"The,......\"The)...\"The...\")...The...\",...The...\"......The...\"...\"...\")......\"The\"......\"...\".........\"...\",......\"...\"............\"...\"........\"...\"\"......\"...............\"..................\"..............\".......()\"...\"...\":\"...\"...\".(...\"...\"(\"...\")\")\")\"...\"(\")\")\"\"...\"(\"(\"...\"...\")\" \"...\"(\"\"(\"(\"()\")\"(\"(\" \"()\")\"\nEpoch: 70, Loss: 0.21326889097690582\nEpoch: 71, Loss: 0.23823411762714386\nEpoch: 72, Loss: 0.20384570956230164\nEpoch: 73, Loss: 0.20348159968852997\nEpoch: 74, Loss: 0.19742974638938904\nEpoch: 75, Loss: 0.19148768484592438\nEpoch: 76, Loss: 0.1902942955493927\nEpoch: 77, Loss: 0.18789424002170563\nEpoch: 78, Loss: 0.18079237639904022\nEpoch: 79, Loss: 0.17420870065689087\nExamples: \n <s><s><s>The the the the The The The the The the theThe the TheTheTheThe theTheThetheTheTheDespite the theDespite theTheIn theTheDespiteTheTheMoreTheTheInTheTheDuring theTheDuringTheTheBaseDespiteTheDespiteDespiteTheInDespiteDespiteDespiteInTheDespiteInDespiteInInInTheDuringInInDespiteDuringInTheInInEachInInOneInOneEachInOneOneOneEachOneOneoneoneoneOneOne one one oneone one oneOne oneoneone one OneOneOne OneOne One One OneOne one One Oneoneone One One one one One oneoneOne oneOne OneoneOne One oneOneoneOneone\nEpoch: 80, Loss: 0.17529720067977905\nEpoch: 81, Loss: 0.16989560425281525\nEpoch: 82, Loss: 0.1669798642396927\nEpoch: 83, Loss: 0.16681791841983795\nEpoch: 84, Loss: 0.16346177458763123\nEpoch: 85, Loss: 0.15988034009933472\nEpoch: 86, Loss: 0.1595904529094696\nEpoch: 87, Loss: 0.15642128884792328\nEpoch: 88, Loss: 0.15295259654521942\nEpoch: 89, Loss: 0.1505340039730072\nExamples: \n <s><s><s>The the the theTheThe theThe thethe theThethe the thethethe thetheThe thebut thethebut theThebut thebutTheTheThebutThebutbutThehitThebutthebutbutbuthitThehitbuthit hit hit hit hits hits hits hit hitshit hits hitshit hit hits hithit hits hit hithit hithithit hit hitting hit hit hitting hits hits hitting hit hitsits hits hitsits hit hitsukes hits hitsukesukesukesitsitsitshit hitsitsitsititsitsutsitsitsinsitsitsupsitsitsingsitsitsisitsitsimsitsitsstitsitsitzitsitsangsitsits thatsitsitsspitsits\nEpoch: 90, Loss: 0.1458851397037506\nEpoch: 91, Loss: 0.14490514993667603\nEpoch: 92, Loss: 0.14239437878131866\nEpoch: 93, Loss: 0.140000119805336\nEpoch: 94, Loss: 0.13946673274040222\nEpoch: 95, Loss: 0.1402091681957245\nEpoch: 96, Loss: 0.13516530394554138\nEpoch: 97, Loss: 0.13197745382785797\nEpoch: 98, Loss: 0.12890730798244476\nEpoch: 99, Loss: 0.13081397116184235\nExamples: \n <s><s>The the the theThe theTheTheThe thethe the thetheThe theDespiteDespiteDespite Despite Despite DespiteDespite DespiteDespiteDespite Regardless Despite Despite Regardless Regardless RegardlessRegardless RegardlessRegardlessRegardless Regardless RegardlessDespite Regardless Regardless.(RegardlessRegardlessRegardlessDespiteRegardless RegardlessDespiteRegardlessRegardless.( RegardlessRegardlessDespiteDespiteRegardlessDespite RegardlessRegardlessThroughoutRegardlessRegardlessThroughout Regardless RegardlessThroughoutRegardless RegardlessThroughout RegardlessRegardless.(Regardless Regardless.( Regardless RegardlessUltimatelyRegardlessRegardlessDuringRegardlessRegardlessIn RegardlessRegardlessDuring Regardless RegardlessIn Regardless RegardlessCont Regardless RegardlessConf Regardless Regardless Cont Regardless Regardless...\" Regardless Regardlessrecogn<pad> RegardlessRegardlessrecogn<pad><pad> Regardless Regardless Conf Conf Conf<pad><pad><pad>Registration<pad><pad>anga<pad><pad>),\" RegardlessRegardlessConf Conf ConfConf ConfConfConfConf Conf<pad>\nEpoch: 100, Loss: 0.1263071596622467\nEpoch: 101, Loss: 0.1237371638417244\nEpoch: 102, Loss: 0.12359829246997833\nEpoch: 103, Loss: 0.12175829708576202\nEpoch: 104, Loss: 0.12121647596359253\nEpoch: 105, Loss: 0.11927033215761185\nEpoch: 106, Loss: 0.11799924075603485\nEpoch: 107, Loss: 0.11607475578784943\nEpoch: 108, Loss: 0.11303239315748215\nEpoch: 109, Loss: 0.113267682492733\nExamples: \n <s><s><s><pad><pad><pad>angaangaanga<pad><pad> 'c'' \"'' ' ''''' hiding''iding<pad>'' hide hiding hiding hiding hidden hiding hidden hidden hiding hiding hide hidden hidden hiddenHidden hidden hidden hide hiddenHiddenHiddenHiddenhiddenHiddenHidden hiddenhidden hidden hiddenhiddenhiddenHidden hiddenHiddenhidden hiddenhiddenHiddenhiddenhidden hiddenHidden unseenHiddenHidden unseen hidden hidden unseenHidden hidden unseen unseen unseen hidden unseen hiddenhidden unseen unseenHidden unseen unseenhiddenHidden unseenhidden hidden unseenhiddenhidden unseen hidden hide unseen unseen seen unseen unseen identified unseen unseen invisible unseen unseen revealed unseen unseenany unseen unseenEach unseen unseen looming unseen unseen<pad>'hidden unseenanyanyany unseenanyone unseen unseen\nEpoch: 110, Loss: 0.11075203120708466\nEpoch: 111, Loss: 0.11069834977388382\nEpoch: 112, Loss: 0.1076396107673645\nEpoch: 113, Loss: 0.10641821473836899\nEpoch: 114, Loss: 0.10486254096031189\nEpoch: 115, Loss: 0.10426218062639236\nEpoch: 116, Loss: 0.10299470275640488\nEpoch: 117, Loss: 0.10041438788175583\nEpoch: 118, Loss: 0.10047705471515656\nEpoch: 119, Loss: 0.09920589625835419\nExamples: \n <s><s><s><pad><pad><pad>angaangaanga<pad><pad> 'c<pad> 'gal 'gal \"c 'c'' 'g'' \"'' ''''' hiding'' hidden'' hide'' hid''iding<pad><pad> \"'hiding hiding'hide hiding'hiding hide hiding hide hide hide hiding hiding hide hidden hide hide hidden hidden hide hidden hiding hidden hidden hidden hiding hiding hidden hide hiding hiddenHidden hidden hiddenhidden hidden hiddenHiddenHiddenHidden hiddenHiddenhiddenHiddenHiddenhiddenhidden hiddenhiddenHidden hiddenhiddenhiddenHiddenhidden hiddenHidden unseen hidden hidden unseenHiddenHidden unseenHidden hidden unseen unseen hidden unseen hiddenhidden unseen unseenHidden unseen unseen unseenhidden hidden unseenhiddenHidden unseenhidden unseen\nEpoch: 120, Loss: 0.09847314655780792\nEpoch: 121, Loss: 0.09674752503633499\nEpoch: 122, Loss: 0.09603092074394226\nEpoch: 123, Loss: 0.09402532130479813\nEpoch: 124, Loss: 0.09547401964664459\nEpoch: 125, Loss: 0.09162093698978424\nEpoch: 126, Loss: 0.09304945915937424\nEpoch: 127, Loss: 0.08964336663484573\nEpoch: 128, Loss: 0.08936836570501328\nEpoch: 129, Loss: 0.08761480450630188\nExamples: \n <s><s><s><pad><pad><pad>angaangaanga<pad><pad> 'c<pad> 'gal 'c'' \"'' ' '''''ig''g'' hiding''iding<pad>'' hid'' hide'' hidden'' obscure'' get'hide hide'hide hiding'hide hidden'hide hid hide hide hiding hide hide hide hidden hide hide hid hidden hidden hide hidden hidden hidden hiding hidden hiddenHidden hidden hiddenhidden hiddenHiddenHiddenHidden hiddenhiddenHiddenHiddenhiddenHidden hiddenHiddenhiddenhidden hidden hidden unseen hidden hidden hid hiddenhiddenhiddenhiddenHiddenhidden hiddenhidden unseenHiddenHidden unseen hiddenHidden unseenHidden hidden unseen unseen hidden unseenHidden unseen unseen unseenhidden hidden unseenhiddenHidden\nEpoch: 130, Loss: 0.08854636549949646\nEpoch: 131, Loss: 0.0861990824341774\nEpoch: 132, Loss: 0.08935561031103134\nEpoch: 133, Loss: 0.08686055988073349\nEpoch: 134, Loss: 0.08318473398685455\nEpoch: 135, Loss: 0.08567377179861069\nEpoch: 136, Loss: 0.08098068833351135\nEpoch: 137, Loss: 0.07993756234645844\nEpoch: 138, Loss: 0.07974325120449066\nEpoch: 139, Loss: 0.07885702699422836\nExamples: \n <s><s><s><pad><pad><pad>ulhu<pad><pad>angaangaanga<pad><pad>Gal<pad><pad>cr<pad><pad>c<pad>cccCcccrcrcrccrccbcc crcc Cubanccclcccomccaccccccccecccicc)...CcCCcCalccCubCcCommccCalCcConfCcciCcCrcCcicCcrcciciciccicrcrciccrcicicrcicr crcrcr crcci crcrci cr crcr cr cr crccr crci crcici crc cr crcic crcrc cr\nEpoch: 140, Loss: 0.07912895828485489\nEpoch: 141, Loss: 0.07815472781658173\nEpoch: 142, Loss: 0.07716391235589981\nEpoch: 143, Loss: 0.07559625059366226\nEpoch: 144, Loss: 0.07501377910375595\nEpoch: 145, Loss: 0.07428063452243805\nEpoch: 146, Loss: 0.074101023375988\nEpoch: 147, Loss: 0.0735662430524826\nEpoch: 148, Loss: 0.07246381044387817\nEpoch: 149, Loss: 0.07254652678966522\nExamples: \n <s><s><s><pad><pad><pad>ulhu<pad><pad> 'c'' \"'' ' ''<pad>'' hiding''''' hidden'' hide'' hid''iding<pad>'hiding hiding'hide hiding'hiding hide hide'hide hide hide hiding hide hidden hide hide hidden hidden hide hiding hidden hide hidden hiding hidden hidden hiddenHiddenHiddenHidden hidden hiddenhidden hidden hidden hid hiddenHidden hiddenhiddenHidden hiddenHiddenhiddenHiddenHiddenhiddenhiddenHiddenhidden hiddenhiddenhidden hiddenHiddenclHiddenHidden unseen hidden hidden unseen hiddenHidden unseenHidden hidden unseen unseen hidden unseenHidden unseen unseen unseenHiddenhidden unseen hiddenhidden unseen unseenhidden hidden unseenhidden unseenHiddenHidden obscure unseen unseen invisible unseen unseen seen unseen unseen\nEpoch: 150, Loss: 0.07139275968074799\nEpoch: 151, Loss: 0.07120381295681\nEpoch: 152, Loss: 0.06887613981962204\nEpoch: 153, Loss: 0.06849848479032516\nEpoch: 154, Loss: 0.0674872100353241\nEpoch: 155, Loss: 0.06792276352643967\nEpoch: 156, Loss: 0.06772693991661072\nEpoch: 157, Loss: 0.06845377385616302\nEpoch: 158, Loss: 0.06517376750707626\nEpoch: 159, Loss: 0.06575329601764679\nExamples: \n <s><s><s><pad><pad><pad> 'c<pad> 'C<pad>'''\"'' '' Cuban''ig''g'' g'' gal''gal''Gal''G'' Gal'' Guy''Gu'' Cast'' Cuba'' CG''gu'' Chick'''''C''ac'' get'' hide'' cover'' hiding'' hidden'' hid''iding''cl'' confidence'' lift'' hold'' raise''Hidden'' obscure''oked''cast''any'' clutch'' hit''hit''uck''</s>\nEpoch: 160, Loss: 0.06544135510921478\nEpoch: 161, Loss: 0.0647110790014267\nEpoch: 162, Loss: 0.0638047456741333\nEpoch: 163, Loss: 0.06363587826490402\nEpoch: 164, Loss: 0.06230349838733673\nEpoch: 165, Loss: 0.06336577981710434\nEpoch: 166, Loss: 0.06089531630277634\nEpoch: 167, Loss: 0.06054309010505676\nEpoch: 168, Loss: 0.06226866692304611\nEpoch: 169, Loss: 0.05958106741309166\nExamples: \n <s><s><s><pad><pad><pad> 'c<pad> 'C<pad>''c'' \"'' '''' ''iding<pad><pad> Cuban''ig'' hiding'' hidden'' hid'' hide'' obscure'' cover'' get'' hold'' confidence'' lift'' raise''Cast'' Cast'' cast''g''Gu''gal'' g'' gal''gu''Gal'' Gal''G'' Guy'''ve''H''any''ac'' clutch''ack''C''cl'' info''hit'' hit''\nEpoch: 170, Loss: 0.059113942086696625\nEpoch: 171, Loss: 0.058581411838531494\nEpoch: 172, Loss: 0.0575859509408474\nEpoch: 173, Loss: 0.05689511075615883\nEpoch: 174, Loss: 0.05858192592859268\nEpoch: 175, Loss: 0.06259912997484207\nEpoch: 176, Loss: 0.056864988058805466\nEpoch: 177, Loss: 0.055183444172143936\nEpoch: 178, Loss: 0.054537493735551834\nEpoch: 179, Loss: 0.05471212789416313\nExamples: \n <s><s><s><pad><pad><pad> 'c<pad> 'C<pad>''c'' \"'' '''' ''iding<pad><pad> Cuban''ig'' hiding'' hidden'' hid'' hide'' obscure'' cover'' get'' hold'' confidence'' lift'' raise'' clutch''gal''g'' gal''Gal'' g'' and''hit'' hit'' kick''uck'' Posted'' Cast<pad><pad>ulhu<pad><pad>road<pad><pad>anga<pad><pad>Registration<pad><pad>),\"'' Cy<pad><pad>cr<pad><pad>abul<pad><pad>ast<pad><pad>udi<pad><pad>C''\nEpoch: 180, Loss: 0.05421973764896393\nEpoch: 181, Loss: 0.06010419502854347\nEpoch: 182, Loss: 0.054103877395391464\nEpoch: 183, Loss: 0.05302005261182785\nEpoch: 184, Loss: 0.05513165518641472\nEpoch: 185, Loss: 0.05249440670013428\nEpoch: 186, Loss: 0.05199015140533447\nEpoch: 187, Loss: 0.051081981509923935\nEpoch: 188, Loss: 0.05166924372315407\nEpoch: 189, Loss: 0.05312906950712204\nExamples: \n <s><s><s><pad><pad><pad> 'c<pad> 'C<pad><pad> c 'c'''\"'' ''<pad>'' gal''gal''Gal'' Gal''ig''g''G'''''Gu''Cal'' Cast''Cast''C''H'' hiding'' hidden'' hid'' hide'' cover''Hidden''iding'' obscure'' get'' confidence'' lift'' hold'' raise'' cast''hit'' hit'' focus''uck'' clutch''ocus''cl<pad> 'g<pad><pad>)...'' info\nEpoch: 190, Loss: 0.051363505423069\nEpoch: 191, Loss: 0.04997773841023445\nEpoch: 192, Loss: 0.049595095217227936\nEpoch: 193, Loss: 0.048951320350170135\nEpoch: 194, Loss: 0.0479452908039093\nEpoch: 195, Loss: 0.04839014634490013\nEpoch: 196, Loss: 0.04870394617319107\nEpoch: 197, Loss: 0.04692528769373894\nEpoch: 198, Loss: 0.048638053238391876\nEpoch: 199, Loss: 0.04585380479693413\nExamples: \n <s><s><s><pad><pad><pad> 'c<pad> 'C<pad><pad> \"c 'c'''\" \"'' ''<pad>''gal'''''Gal'''ve'' gal''g''ig'' g''G'' hiding'' hidden'' hid'' hide'' cover'' get'' hold'' raise'' lift'' drop''iding<pad><pad>cl<pad><pad>),\"''cl<pad> 'gal<pad><pad>cr<pad><pad>anga<pad><pad>amac<pad><pad>abul<pad><pad>ulhu<pad><pad>ast<pad><pad>real<pad><pad>Registration<pad><pad>Camp<pad><pad>Conf<pad><pad>C'' Chick<pad><pad>Bi<pad><pad>\nEpoch: 200, Loss: 0.052753474563360214\n"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = nlp.load_dataset('wmt_t2t')\n",
    "model = transformers.BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)\n",
    "tokenizer = transformers.BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "dl = DataLoader(dataset['train'], batch_size=10)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)\n",
    "\n",
    "epochs = 201\n",
    "max_len = 50\n",
    "\n",
    "data = next(iter(dl))\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    en_tokenized_data = tokenizer.batch_encode_plus(\n",
    "        data['translation']['en'],\n",
    "        max_length=max_len, \n",
    "        truncation=True,\n",
    "        pad_to_max_length=True, \n",
    "        return_attention_mask=True, \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    en_tokenized_data = en_tokenized_data.to(device)\n",
    "    \n",
    "    if e % 10 == 0:\n",
    "        model.eval()\n",
    "        generated_examples = model.generate(en_tokenized_data['input_ids'], \n",
    "                                            attention_mask=en_tokenized_data['attention_mask'], \n",
    "                                            decoder_start_token_id=tokenizer.bos_token_id)\n",
    "        print(f\"Examples: \\n\", tokenizer.batch_decode(generated_examples)[0])\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    result = model(\n",
    "        input_ids=en_tokenized_data['input_ids'],\n",
    "        attention_mask=en_tokenized_data['attention_mask'],\n",
    "        decoder_input_ids=en_tokenized_data['input_ids'],\n",
    "        decoder_attention_mask=en_tokenized_data['attention_mask'],\n",
    "        labels=en_tokenized_data['input_ids']\n",
    "    )\n",
    "\n",
    "    loss, output, output2 = result[:3]\n",
    "    print(f\"Epoch: {e}, Loss: {loss.item()}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos resultados obtidos vs resultados esperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(\n",
    "    input_ids=en_tokenized_data['input_ids'],\n",
    "    attention_mask=en_tokenized_data['attention_mask'],\n",
    "    decoder_input_ids=en_tokenized_data['input_ids'],\n",
    "    decoder_attention_mask=en_tokenized_data['attention_mask'],\n",
    "    labels=en_tokenized_data['input_ids']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(torch.Size([10, 50, 50264]), torch.Size([10, 50]))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "loss, logits = result[0].cpu(), result[1].cpu()\n",
    "inputs = en_tokenized_data['input_ids'].cpu()\n",
    "logits.shape, inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados do método `model.generate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[\"</s><s><s>Resumptionumptionumption suspension suspension suspensionumption suspensionumptionumptionResumption suspension cabin<pad><pad><pad>\\xa0c<pad><pad> 'c 'C'' ''''\\xa0 '\\xa0' 'C' 'ig 'g''g' 'gig'' g''G' 'G''Gu''igigg 'gg 'igaggggigggG 'gagg 'Gg 'gal 'gagi 'gagu 'g gggagaggigag 'gaggingggagiggGugagiagiagigagiaggagGgagiGuGagagiagiGagiagiGuGuagiagi\"]"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tokenizer.batch_decode(model.generate(inputs[:1].cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['</s><s><s><s>The The The The the The TheThe TheTheTheThe the theThe The theThe theTheThethetheThetheTheTheDespiteTheThebutThebut thebutbutbut theThebutbut...but.Thebut.but)...but......but....but......but......but...)...but)...)...)...but...)...)......)............)......)...)......\"but......\"...)...............)...............,...).........,...)...)........)...........)...)...\"...)...)...,...)......\")......\"...\"......\"...\"...................\"...\"bek<pad><pad><pad>)...\"...<pad><pad> \\'<pad><pad>']"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "tokenizer.batch_decode(model.generate(torch.argmax(torch.nn.functional.softmax(logits[:1].cuda(), dim=-1), dim=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados da saída do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[    0, 20028, 21236,     9,     5,  1852,     2,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "inputs[:1].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[    0, 20028, 21236,     9,     5,  1852,     2,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "torch.argmax(torch.nn.functional.softmax(output[:1].cpu(), dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('3.8.5': pyenv)",
   "language": "python",
   "name": "python38564bit385pyenv15b540295b4f4efd9a044469a2d20dc8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}