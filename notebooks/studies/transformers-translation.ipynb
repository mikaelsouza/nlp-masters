{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp, transformers, torch, tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "<s><s><s><pad><pad><pad>angaangaangaacacacabacaccacacaciacacancacacapacacAcacacacaacac ChickacacCacacACacacicacacciacac Tacacacaciesacacacyacacaclacacicasacaccasacaccracac acacclacacicaacacccacac cracacacanacaccapacacjacacaccuacacamacacac Acacaccatacac)...acacocalacacchiacac Cubanacacicanacac ACacacCapacacacciacacCubacacCatacacCamacac camacac</s>\nEpoch: 740, Loss: 0.19808423519134521\nEpoch: 741, Loss: 0.19004777073860168\nEpoch: 742, Loss: 0.19002141058444977\nEpoch: 743, Loss: 0.19766700267791748\nEpoch: 744, Loss: 0.19140496850013733\nEpoch: 745, Loss: 0.18866917490959167\nEpoch: 746, Loss: 0.1875365674495697\nEpoch: 747, Loss: 0.1900414377450943\nEpoch: 748, Loss: 0.1918729990720749\nEpoch: 749, Loss: 0.18556812405586243\nExamples: \n <s><s><s><pad><pad><pad>angaangaangaacacacabacaccacacaciacacancacacapacacAcacacacaacac ChickacacCacacACacacicacacciacac Tacacacaciesacacaclacacicasacacccacaccasacaccracac acacclacac cracacacanacacicaacaccapaciacicaciacaciaciaciac cacaciacaacicicacicciacciaciacciciacaciciaciaciciacic cicacaciicicicciaciciciciicicaciaciicciiccici</s>\nEpoch: 750, Loss: 0.1860123723745346\nEpoch: 751, Loss: 0.18579372763633728\nEpoch: 752, Loss: 0.18745087087154388\nEpoch: 753, Loss: 0.187320277094841\nEpoch: 754, Loss: 0.18434832990169525\nEpoch: 755, Loss: 0.18964074552059174\nEpoch: 756, Loss: 0.18963570892810822\nEpoch: 757, Loss: 0.180388942360878\nEpoch: 758, Loss: 0.18694768846035004\nEpoch: 759, Loss: 0.18185816705226898\nExamples: \n <s><s><s><pad><pad><pad>angaangaangaacacacabacaccacacaciacacancacacapacacAcacacacaacac ChickacacCacacACacacicacacaciesacacciacac Tacacacicasacacaclacaccasacacacanacaccracac acacclacacicaacacccacaccapacac cracacamacacacjacacaccuacac AcacacCapacaccatacacCassacacCalacacCracacCamacacCasacacCubacacCatacac)...CacaciaciacCicacaciCicaciaciC</s>\nEpoch: 760, Loss: 0.1866670846939087\nEpoch: 761, Loss: 0.18603858351707458\nEpoch: 762, Loss: 0.18147553503513336\nEpoch: 763, Loss: 0.1781490445137024\nEpoch: 764, Loss: 0.1799379587173462\nEpoch: 765, Loss: 0.1774732619524002\nEpoch: 766, Loss: 0.18470045924186707\nEpoch: 767, Loss: 0.17921176552772522\nEpoch: 768, Loss: 0.18500696122646332\nEpoch: 769, Loss: 0.18412664532661438\nExamples: \n <s><s><s><pad><pad><pad>angaangaangaacacacabacaccacacaciacacancacacapacacAcacacacaacac ChickacacCacacACacacicacacaciesacacciacac Tacacacicasacacaclacaccasacacacanacaccracac acacclacacicaacacccacaccapacac cracacamacacacjacacaccuacac AcacacCapacaccatacacCassacacCalacacCracacCamacacCasacacCubacacCatacac)...CacaciaciacCicacaciCicaciaciC</s>\nEpoch: 770, Loss: 0.18898223340511322\nEpoch: 771, Loss: 0.17810571193695068\nEpoch: 772, Loss: 0.17786598205566406\nEpoch: 773, Loss: 0.17820963263511658\nEpoch: 774, Loss: 0.18364167213439941\nEpoch: 775, Loss: 0.18131421506404877\nEpoch: 776, Loss: 0.17738372087478638\nEpoch: 777, Loss: 0.17605286836624146\nEpoch: 778, Loss: 0.178029403090477\nEpoch: 779, Loss: 0.17419712245464325\nExamples: \n <s><s><s><pad><pad><pad>angaangaangaacacacabacacapacacaciacacAcacacacaacacancacapcacac Acacacacanacac Acadacaciaciaciacancaciacaciancacacciacacicaciacciaciacicacaciciacaciacanacaci Chickacac ChickacaciCaciaciciaciaciCicaciciciciacicicicaciaci Chickaciaciicicciciaciciicicacicciaccici've Chickacici'veaciaciicanacci've'veaciicanaciaci've'veciicanacicibicic've've've'd've</s>\nEpoch: 780, Loss: 0.17930133640766144\nEpoch: 781, Loss: 0.177775040268898\nEpoch: 782, Loss: 0.17728714644908905\nEpoch: 783, Loss: 0.17179431021213531\nEpoch: 784, Loss: 0.1708979308605194\nEpoch: 785, Loss: 0.1698780506849289\nEpoch: 786, Loss: 0.17432428896427155\nEpoch: 787, Loss: 0.17648769915103912\nEpoch: 788, Loss: 0.177869513630867\nEpoch: 789, Loss: 0.17639997601509094\nExamples: \n <s><s><s><pad><pad><pad>angaangaangaacacacabacaccacacaciacacancacacapacacAcacacacaacacicacacciacac Chickacacacanacac TacacacCacacACacacaclacac)...CacicicicacaciaciaciaccaciacicaciacaciCicicciaciacciaciaciciacaciciciciacciciaciciicicacicicciaciccicicicicibicicicacici)...CicicaniciccicaciaciiciciliciciCicacicicaicicicasciciicci</s>\nEpoch: 790, Loss: 0.17376314103603363\nEpoch: 791, Loss: 0.16780182719230652\nEpoch: 792, Loss: 0.17516562342643738\nEpoch: 793, Loss: 0.16962884366512299\nEpoch: 794, Loss: 0.16729266941547394\nEpoch: 795, Loss: 0.1827528178691864\nEpoch: 796, Loss: 0.17128509283065796\nEpoch: 797, Loss: 0.17235173285007477\nEpoch: 798, Loss: 0.1694665551185608\nEpoch: 799, Loss: 0.16717249155044556\nExamples: \n <s><s><s><pad><pad><pad>angaangaangaacacacabacaccacacaciacacancacacapacacAcacacacaacacicacacciacac ChickacacacanacacCacacACacacaclacaccapacaccracac cracaccasacacclacac Tacacacccacacchiacac cacaciaciacicicicacicciacic cicaciacaciicicaciaciaciicacciaciacciciacciicicciaciaciciacaciciciciaciciaciiccici ciacacaaciaciaclacicicacici</s>\nEpoch: 800, Loss: 0.167469784617424\nEpoch: 801, Loss: 0.16925813257694244\nEpoch: 802, Loss: 0.17244952917099\nEpoch: 803, Loss: 0.1646127998828888\nEpoch: 804, Loss: 0.1679050177335739\nEpoch: 805, Loss: 0.16561593115329742\nEpoch: 806, Loss: 0.16660280525684357\nEpoch: 807, Loss: 0.1689353585243225\nEpoch: 808, Loss: 0.1791929006576538\nEpoch: 809, Loss: 0.1686123013496399\nExamples: \n <s><s><s><pad><pad><pad>angaangaangaacacacabacacapacacaciacacAcacacacaacacancacapcacac Acacacacanacac ChickacacACacac AcadacacCacaccacaciaciaciacicacacciacacicaciacciaciacaciciacicicaciaciciciacaciicicicciacciciaciciaciaciiccicicicicciiciciliciciiciciCicacaciicanciciicciiliciiicicibiciciiliciiciliiciliiliiliciiliiliiciiliiiliili</s>\nEpoch: 810, Loss: 0.16594883799552917\nEpoch: 811, Loss: 0.18018968403339386\nEpoch: 812, Loss: 0.1643926352262497\nEpoch: 813, Loss: 0.16984616219997406\nEpoch: 814, Loss: 0.17232459783554077\nEpoch: 815, Loss: 0.16910485923290253\nEpoch: 816, Loss: 0.1671271026134491\nEpoch: 817, Loss: 0.1682862937450409\nEpoch: 818, Loss: 0.16594861447811127\nEpoch: 819, Loss: 0.17669841647148132\nExamples: \n <s><s><s><pad><pad><pad>angaangaangaacacacangaacangaangaapacacapacangaaciacacabacacaciacapcacacancacacAcacacacaacacacanacaccapacaccacaciaciacaciacaacaciacanacaciangaacaciaclacacciacacicaciacancaciacicacac Chickacac acacACacacaciesacac Tacacacicasacacagiacacicaacacicanacaccasacac cracacamacacac Acadacac Acacac ACacacCacacacyacacCapacac)...acac 'acacaclac</s>\nEpoch: 820, Loss: 0.16765642166137695\nEpoch: 821, Loss: 0.16364358365535736\nEpoch: 822, Loss: 0.16534428298473358\nEpoch: 823, Loss: 0.16796769201755524\nEpoch: 824, Loss: 0.15986871719360352\nEpoch: 825, Loss: 0.16484056413173676\nEpoch: 826, Loss: 0.16169597208499908\nEpoch: 827, Loss: 0.1618492752313614\nEpoch: 828, Loss: 0.16238486766815186\nEpoch: 829, Loss: 0.17260292172431946\nExamples: \n <s><s><s><pad><pad><pad>st<pad>ststac<pad>stacastacstacstcstacStacststCStStStCstCstStStStarStStstStarStStarStarStstStStarCstStarStarStarStarsStStastStarStStarsStarStarCastStStStarsStarsStarsStarStarsStars...\"ststStstststastStstastStarStar...\"stastastastStarststStarstStastastStStSTSTSTStStSaintStStestStSt\"...StstSTSTStarStSaintstStSTStStarStars...\"Stst...\"StarstSTStSTStarStarstaststSt...\"St</s>\nEpoch: 830, Loss: 0.1603575199842453\nEpoch: 831, Loss: 0.16844512522220612\nEpoch: 832, Loss: 0.15738970041275024\nEpoch: 833, Loss: 0.15958468616008759\nEpoch: 834, Loss: 0.16086380183696747\nEpoch: 835, Loss: 0.15788494050502777\nEpoch: 836, Loss: 0.1590610295534134\nEpoch: 837, Loss: 0.16087554395198822\nEpoch: 838, Loss: 0.16149984300136566\nEpoch: 839, Loss: 0.15526919066905975\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststaststststStStStststSTStStSTStstStstSTSTSTstStSTSTStSTstSTststStarStstestStstStarststestststIntststastStstastSTstestesteststStaststestastastestestasteststastostststostestestosteststostoststastestaststoststestostostostastastostostestastostestoststostastestostaststastsststingsststkeepstst stststastsestestastsstestastseststastsast</s>\nEpoch: 840, Loss: 0.16536866128444672\nEpoch: 841, Loss: 0.16393651068210602\nEpoch: 842, Loss: 0.15837156772613525\nEpoch: 843, Loss: 0.15454863011837006\nEpoch: 844, Loss: 0.15543833374977112\nEpoch: 845, Loss: 0.15907368063926697\nEpoch: 846, Loss: 0.1614026129245758\nEpoch: 847, Loss: 0.1549888402223587\nEpoch: 848, Loss: 0.15249335765838623\nEpoch: 849, Loss: 0.15956231951713562\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStStStstStstSTststSTStStSTSTSTstSTSTStSTstStSTStStarStststStarStStastStStestStStStarStarStSTStarStastastStstestStstStarStarSTStstastStarStarStarStarsStst...\"StstRegardlessStstSaintStstInStstIntStstostStst\"...StstThroughoutStstDespiteStstDuringStstSplitStstIncludesStstAmidStstStillStStInStStSaintStStIntIntIntInIntInStestStarIntIntStSt</s>\nEpoch: 850, Loss: 0.15404154360294342\nEpoch: 851, Loss: 0.16860249638557434\nEpoch: 852, Loss: 0.15223132073879242\nEpoch: 853, Loss: 0.152357816696167\nEpoch: 854, Loss: 0.1563982516527176\nEpoch: 855, Loss: 0.15369699895381927\nEpoch: 856, Loss: 0.1569604128599167\nEpoch: 857, Loss: 0.15482711791992188\nEpoch: 858, Loss: 0.15772196650505066\nEpoch: 859, Loss: 0.16004039347171783\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStStStstStstSTststSTStStSTSTSTstSTSTStSTstStSTStStarStststStarStStastStStestStStStarStarStSTStarStastastStstestStstStarStarSTStstastStarStarStarStarsStst...\"StstRegardlessStstSaintStstInStstIntStstostStst\"...StstThroughoutStstDespiteStstDuringStstSplitStstIncludesStstAmidStstStillStStInStStSaintStStIntIntIntInIntInStestStarIntIntStSt</s>\nEpoch: 860, Loss: 0.15305578708648682\nEpoch: 861, Loss: 0.15380845963954926\nEpoch: 862, Loss: 0.1538476198911667\nEpoch: 863, Loss: 0.15625084936618805\nEpoch: 864, Loss: 0.14851002395153046\nEpoch: 865, Loss: 0.1512623280286789\nEpoch: 866, Loss: 0.1493939310312271\nEpoch: 867, Loss: 0.15765433013439178\nEpoch: 868, Loss: 0.1508464217185974\nEpoch: 869, Loss: 0.1535097360610962\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStStStstStstSTststSTStStSTSTSTstSTSTStSTstStSTStStarStststStarStStastStStestStStStarStarStSTStarStastastStstestStstStarStarSTStstastStarStarStarStarsStst...\"StstRegardlessStstSaintStstInStstIntStstostStst\"...StstThroughoutStstDespiteStstDuringStstSplitStstIncludesStstAmidStstStillStStInStStSaintStStIntIntIntInIntInStestStarIntIntStSt</s>\nEpoch: 870, Loss: 0.1553344875574112\nEpoch: 871, Loss: 0.149368554353714\nEpoch: 872, Loss: 0.1750880926847458\nEpoch: 873, Loss: 0.15082107484340668\nEpoch: 874, Loss: 0.14768220484256744\nEpoch: 875, Loss: 0.1492009162902832\nEpoch: 876, Loss: 0.14941571652889252\nEpoch: 877, Loss: 0.14583426713943481\nEpoch: 878, Loss: 0.14715707302093506\nEpoch: 879, Loss: 0.1498650312423706\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStStStstStstSTststSTStStSTSTSTstSTSTStSTstStSTStStarStststStarStStastStStestStStStarStarStSTStarStastastStstestStstStarStarSTStstastStarStarStarStarsStst...\"StstRegardlessStstSaintStstInStstIntStstostStst\"...StstThroughoutStstDespiteStstDuringStstSplitStstIncludesStstAmidStstEachStstStillStStIntStStSaintStStInStIntIntStStarIntIntInSt</s>\nEpoch: 880, Loss: 0.14529070258140564\nEpoch: 881, Loss: 0.15763096511363983\nEpoch: 882, Loss: 0.1504620611667633\nEpoch: 883, Loss: 0.1453593671321869\nEpoch: 884, Loss: 0.14634095132350922\nEpoch: 885, Loss: 0.14795641601085663\nEpoch: 886, Loss: 0.15003307163715363\nEpoch: 887, Loss: 0.14539624750614166\nEpoch: 888, Loss: 0.14627036452293396\nEpoch: 889, Loss: 0.15447303652763367\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStstSTSTSTststSTstStSTSTStSTstSTStstStarStStStarStststIntststastStstestStStestStstIntStStastStStSaintStStIntstStestestestSteststesteststStaststStIntStstostestestSTstIntIntstestIntstIntestIntIntStIntIntInt...\"Stst...\"StastastStSTastastSTstestSTSTestStIntSTSTaststSTestestastSTSTIntstST</s>\nEpoch: 890, Loss: 0.14727674424648285\nEpoch: 891, Loss: 0.14717505872249603\nEpoch: 892, Loss: 0.14402179419994354\nEpoch: 893, Loss: 0.14578494429588318\nEpoch: 894, Loss: 0.14427930116653442\nEpoch: 895, Loss: 0.14190442860126495\nEpoch: 896, Loss: 0.14787431061267853\nEpoch: 897, Loss: 0.1427994668483734\nEpoch: 898, Loss: 0.14178261160850525\nEpoch: 899, Loss: 0.14787936210632324\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStststSTSTSTStstSTstSTStSTSTstStSTstStarStStStarStstStarStarStStarStarStarststStarstStStarstSTStarstestStstestesteststStastStStestestStStastastestestaststSteststestastastStstaststestSTststSaintStStSaintStstSaintststasteststSTestestSTSTeststastStestStSTestStestSTestSTStStarSTSTastastSTSTSaintStST</s>\nEpoch: 900, Loss: 0.14414943754673004\nEpoch: 901, Loss: 0.14297300577163696\nEpoch: 902, Loss: 0.1427956223487854\nEpoch: 903, Loss: 0.1510055959224701\nEpoch: 904, Loss: 0.14785946905612946\nEpoch: 905, Loss: 0.1563807725906372\nEpoch: 906, Loss: 0.14140896499156952\nEpoch: 907, Loss: 0.14405295252799988\nEpoch: 908, Loss: 0.14529383182525635\nEpoch: 909, Loss: 0.146852508187294\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStststSTSTSTStstSTstSTStSTSTstStSTstStarStStStarStstStarStarStStarStarStarststStarstStStarstSTStarstestStstestesteststStastStStSaintStStestestStStastastestestastastStstSaintStStarSTSTStarStSTestestSTSTestStSTStarStarIntStStIntStStarIntIntIntInStSt...\"Stst...\"StaststestaststSteststestSTststIntIntStst</s>\nEpoch: 910, Loss: 0.1390206217765808\nEpoch: 911, Loss: 0.13994504511356354\nEpoch: 912, Loss: 0.14658863842487335\nEpoch: 913, Loss: 0.13748560845851898\nEpoch: 914, Loss: 0.14386001229286194\nEpoch: 915, Loss: 0.13712447881698608\nEpoch: 916, Loss: 0.13943170011043549\nEpoch: 917, Loss: 0.14142215251922607\nEpoch: 918, Loss: 0.13681426644325256\nEpoch: 919, Loss: 0.1384609192609787\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStststSTSTSTStstSTstSTStSTSTstStSTstStarStStStarStstStarStarStSTStarStStarStarStarStarsStStastStStSaintStStestStStIntStSt...\"StaststStastastStstestStstSaintStstIntStst...\"StstaststestesteststIntstst...\"IntstastSTststastestest...\"Intastasteststestaststings...\"Intestastastastsststingsstestingsststastsstastsasts</s>\nEpoch: 920, Loss: 0.14064764976501465\nEpoch: 921, Loss: 0.14689601957798004\nEpoch: 922, Loss: 0.13715186715126038\nEpoch: 923, Loss: 0.1395975798368454\nEpoch: 924, Loss: 0.13591985404491425\nEpoch: 925, Loss: 0.1384032666683197\nEpoch: 926, Loss: 0.14970256388187408\nEpoch: 927, Loss: 0.14192622900009155\nEpoch: 928, Loss: 0.15026289224624634\nEpoch: 929, Loss: 0.14420823752880096\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStststSTSTSTStstSTstSTStSTSTstStSTstStarStStStarStstStarStarStStarStarStarststStarstStStarstastStStestStarstestStStastStstestesteststStestestStstSaintStStIntStStSaintststSaintstStastastestestSaintStstIntStestStestastastSteststestSTStestSTestestaststStIntestestSTSTestastestStIntIntIntestIntIntInIntIntSt</s>\nEpoch: 930, Loss: 0.13384544849395752\nEpoch: 931, Loss: 0.13178081810474396\nEpoch: 932, Loss: 0.13716429471969604\nEpoch: 933, Loss: 0.1376596987247467\nEpoch: 934, Loss: 0.13624335825443268\nEpoch: 935, Loss: 0.14036914706230164\nEpoch: 936, Loss: 0.1365424245595932\nEpoch: 937, Loss: 0.13489405810832977\nEpoch: 938, Loss: 0.133077472448349\nEpoch: 939, Loss: 0.1337258517742157\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStststSTstStSTSTstSTSTSTStstSTStStarStstStarStStStarStarStastStStestStStastastStstestesteststStestestStstastestestSTststaststestastasteststestostststostestestosteststoststestStaststStastSTstestSTSTestestaststSTestSTStSTestStSTstastSTSTastastSTStestSTeststSTastSTestastStastestSTastStST</s>\nEpoch: 940, Loss: 0.13059157133102417\nEpoch: 941, Loss: 0.1415567249059677\nEpoch: 942, Loss: 0.13227897882461548\nEpoch: 943, Loss: 0.13838689029216766\nEpoch: 944, Loss: 0.13368839025497437\nEpoch: 945, Loss: 0.136747807264328\nEpoch: 946, Loss: 0.14495109021663666\nEpoch: 947, Loss: 0.13498760759830475\nEpoch: 948, Loss: 0.13127154111862183\nEpoch: 949, Loss: 0.13601796329021454\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStstSTSTSTststSTstSTStSTSTStstStarStStStarStststIntstStSTstStestStstestStStastStstIntStst...\"StstSaintStStSaintStstastStStestSTstIntSTstestesteststSTestestSTSTestStestestStIntStStIntIntIntStestIntIntstIntIntInIntInt...\"StStSmartStstSmartStStInStSt stStSt...\"StastastStIntSTStIntInStstIn</s>\nEpoch: 950, Loss: 0.13337655365467072\nEpoch: 951, Loss: 0.14002008736133575\nEpoch: 952, Loss: 0.12751711905002594\nEpoch: 953, Loss: 0.13222332298755646\nEpoch: 954, Loss: 0.13436752557754517\nEpoch: 955, Loss: 0.13085678219795227\nEpoch: 956, Loss: 0.13118499517440796\nEpoch: 957, Loss: 0.1309107095003128\nEpoch: 958, Loss: 0.1344602406024933\nEpoch: 959, Loss: 0.13259947299957275\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStstSTSTSTststSTstSTStSTSTStstStarStStStarStststIntstStSTstStestStstestStStIntststastStStastStstIntStStesteststestestestSTstIntIntIntstestIntstIntestIntIntestintIntIntInIntInt IntIntitIntIntitsIntIntintitIntitintitintitsIntitititIntitsintitititsIntitsititsintitsitsitsinsitsinsititsitsitinsits</s>\nEpoch: 960, Loss: 0.12844766676425934\nEpoch: 961, Loss: 0.12941429018974304\nEpoch: 962, Loss: 0.12645040452480316\nEpoch: 963, Loss: 0.13455522060394287\nEpoch: 964, Loss: 0.13424360752105713\nEpoch: 965, Loss: 0.13064523041248322\nEpoch: 966, Loss: 0.12928731739521027\nEpoch: 967, Loss: 0.1295357495546341\nEpoch: 968, Loss: 0.13002249598503113\nEpoch: 969, Loss: 0.1326850801706314\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStstSTSTSTststSTstSTStSTSTStstStarStStStarStststIntstStSTstStestStstestStStIntststastStstIntStst...\"ststStarstStastStStSaintStstSaintStStSmartStStestestestSteststesteststStStarStarStSTestestastastestestSTStStarIntStStastastStestStarStaststStIntStestSTSTestStIntIntIntStIntInStSt...\"StastStarSt</s>\nEpoch: 970, Loss: 0.12451918423175812\nEpoch: 971, Loss: 0.12712205946445465\nEpoch: 972, Loss: 0.12456811219453812\nEpoch: 973, Loss: 0.12764117121696472\nEpoch: 974, Loss: 0.1275336891412735\nEpoch: 975, Loss: 0.13028651475906372\nEpoch: 976, Loss: 0.12710784375667572\nEpoch: 977, Loss: 0.12816698849201202\nEpoch: 978, Loss: 0.13341040909290314\nEpoch: 979, Loss: 0.12600469589233398\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStstSTSTSTststSTstSTStSTSTStstStarStStStarStststIntstStSTstStestStstestStStastStstIntStst...\"StstSaintStStSaintStstastStStestSTstestestestSTSTesteststStastastStestestSteststestSTeststSTestStSTestastastestestaststStIntStStSmartStStIntSTStIntIntIntStStarIntIntInIntIntBestStSt...\"StastStarStast</s>\nEpoch: 980, Loss: 0.12838895618915558\nEpoch: 981, Loss: 0.12684015929698944\nEpoch: 982, Loss: 0.13662873208522797\nEpoch: 983, Loss: 0.1278030127286911\nEpoch: 984, Loss: 0.12616989016532898\nEpoch: 985, Loss: 0.1268235296010971\nEpoch: 986, Loss: 0.1264033317565918\nEpoch: 987, Loss: 0.12202771753072739\nEpoch: 988, Loss: 0.12188256531953812\nEpoch: 989, Loss: 0.12771306931972504\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststStStStSTStStstStstSTStststSTSTSTstSTstStSTSTStSTststestststIntstst...\"ststaststSt stststostststthststkeepststingsststastsststainsststustststspstststaffstesteststestingsstestastsstestSTstastSTstestStstastStstestSaintstst ststStestStStSaintStStStarStstStarStStIntStStestestSteststStIntstStastastStStInStSt</s>\nEpoch: 990, Loss: 0.12686210870742798\nEpoch: 991, Loss: 0.12462470680475235\nEpoch: 992, Loss: 0.1304759979248047\nEpoch: 993, Loss: 0.1272042691707611\nEpoch: 994, Loss: 0.12151414901018143\nEpoch: 995, Loss: 0.12766024470329285\nEpoch: 996, Loss: 0.12241532653570175\nEpoch: 997, Loss: 0.12381552159786224\nEpoch: 998, Loss: 0.12525518238544464\nEpoch: 999, Loss: 0.12326429039239883\nExamples: \n <s><s><s><pad><pad><pad>st<pad>stastastaststststestststStstStStStSTStStstSTstStSTststSTSTSTStSTSTstSTStststStarStStStarStstestStstStarStarStastStStestStStaststestesteststSteststestSTstStarststaststStStarstStastastestestSTStStarStarstSTestestastastSTSTestStStarSTSTastastStestStarStestestStestSTestSTSTStarStSTestStarStarSTStestastStstSaintStStIntStStInStStSaintSt</s>\nEpoch: 1000, Loss: 0.12634266912937164\n"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = nlp.load_dataset('wmt_t2t')\n",
    "model = transformers.BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)\n",
    "tokenizer = transformers.BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "dl = DataLoader(dataset['train'], batch_size=10)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.000001)\n",
    "\n",
    "epochs = 1001\n",
    "max_len = 50\n",
    "\n",
    "data = next(iter(dl))\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    en_tokenized_data = tokenizer.batch_encode_plus(\n",
    "        data['translation']['en'],\n",
    "        max_length=max_len, \n",
    "        truncation=True,\n",
    "        pad_to_max_length=True, \n",
    "        return_attention_mask=True, \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    en_tokenized_data = en_tokenized_data.to(device)\n",
    "    \n",
    "    if e % 10 == 0:\n",
    "        model.eval()\n",
    "        generated_examples = model.generate(en_tokenized_data['input_ids'], \n",
    "                                            attention_mask=en_tokenized_data['attention_mask'], \n",
    "                                            decoder_start_token_id=tokenizer.bos_token_id)\n",
    "        print(f\"Examples: \\n\", tokenizer.batch_decode(generated_examples)[0])\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    result = model(\n",
    "        input_ids=en_tokenized_data['input_ids'],\n",
    "        attention_mask=en_tokenized_data['attention_mask'],\n",
    "        decoder_input_ids=en_tokenized_data['input_ids'],\n",
    "        decoder_attention_mask=en_tokenized_data['attention_mask'],\n",
    "        labels=en_tokenized_data['input_ids']\n",
    "    )\n",
    "\n",
    "    loss, output, output2 = result[:3]\n",
    "    print(f\"Epoch: {e}, Loss: {loss.item()}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos resultados obtidos vs resultados esperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(\n",
    "    input_ids=en_tokenized_data['input_ids'],\n",
    "    attention_mask=en_tokenized_data['attention_mask'],\n",
    "    decoder_input_ids=en_tokenized_data['input_ids'],\n",
    "    decoder_attention_mask=en_tokenized_data['attention_mask'],\n",
    "    labels=en_tokenized_data['input_ids']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(torch.Size([10, 50, 50264]), torch.Size([10, 50]))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "loss, logits = result[0].cpu(), result[1].cpu()\n",
    "inputs = en_tokenized_data['input_ids'].cpu()\n",
    "logits.shape, inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['</s><s><s><s>Resumption of of of the of the the session session sessionsession sessionsessionsession session session sessions session sessionSession session session Session session session resume session session.Resumptionumptionumption resumedumption resumed resumed resumedumption resume resume resumeumption resumed resume resume resumed resumed resumeumptionumption resumeumption resume resumed resume session suspension resume session resume resume']"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tokenizer.batch_decode(model.generate(inputs[:1].cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['</s><s>Resumptionumption of of of the of the the session session sessionsession session sessionSession session session sessions session sessions sessions session session.Session sessionSessionSessionSession sessionsessionSessionSessionsessionSession session SessionSessionSessionrapSessionSession SessionSession Session sessionSessionResumptionResumptionSessionSessionRepSessionSessionSnapSnapSnapResResResSessionResResumptionRepResResumpResResRepResRecResResReportsResResPsResRespsResRes)\",ResRes),\"ResResumpsResResSpotResResspResRes.\"\"ResRes<pad><pad><pad> \\'Res<pad>\\'\\'Res \\'ResRes\\xa0Rep\\xa0 \\'Res \"\\'\\'\\'Res\\xa0\\'\\' \"\\'\" \" \\'\\xa0Res \\'']"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "tokenizer.batch_decode(model.generate(torch.argmax(torch.nn.functional.softmax(logits[:1].cuda(), dim=-1), dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('3.8.5': pyenv)",
   "language": "python",
   "name": "python38564bit385pyenv15b540295b4f4efd9a044469a2d20dc8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}