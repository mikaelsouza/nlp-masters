{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Seq2Seq Networks using Pytorch\n",
    "\n",
    "https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb\n",
    "\n",
    "Nesse notebook irei realizar um pretreino da rede com atenção para traduzir frases de inglês -> inglês e depois aplicar o encoder aprendido na rede de pontuação.\n",
    "\n",
    "Compararei os resultados da função de perda e perplexidade para verificar se houve alguma melhoria nos resultados por conta desse pre-treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k, IWSLT\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.0.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.17.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.42.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.17.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (41.0.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.42.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
      "You can now load the model via spacy.load('de')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en_punc(text):\n",
    "    r = list()\n",
    "    for tok in spacy_en.tokenizer(text):\n",
    "        if tok.text in string.punctuation:\n",
    "            try:\n",
    "                r.pop()\n",
    "            except:\n",
    "                pass\n",
    "            r.append(tok.text)\n",
    "        else:\n",
    "            r.append(' ')\n",
    "    return r\n",
    "\n",
    "def tokenize_en(text):\n",
    "    r = list()\n",
    "    for tok in spacy_en.tokenizer(text):\n",
    "        if tok.text in string.punctuation:\n",
    "            continue\n",
    "        else:\n",
    "            r.append(tok.text)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize_en,\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            lower=True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize_en_punc,\n",
    "            init_token='<sos>',\n",
    "            eos_token='<eos>',\n",
    "            lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Multi30k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b1478e449f28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.en'),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                     fields=(SRC, TRG))\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m auto_train_data, auto_valid_data, auto_test_data = Multi30k.splits(exts=('.en', '.en'),\n\u001b[1;32m      5\u001b[0m                                                     fields=(SRC, SRC))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Multi30k' is not defined"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.en'),\n",
    "                                                    fields=(SRC, TRG))\n",
    "\n",
    "auto_train_data, auto_valid_data, auto_test_data = Multi30k.splits(exts=('.en', '.en'),\n",
    "                                                    fields=(SRC, SRC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['two', 'young', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes'], 'trg': [' ', ',', ' ', ' ', ' ', ' ', ' ', ' ', '.']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'two young, white males are outside near many bushes. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_complete_example(example):\n",
    "    sentence = ''\n",
    "    for src, trg in zip(example['src'], example['trg']):\n",
    "        sentence += src\n",
    "        if trg != ' ':\n",
    "            trg += ' '\n",
    "        sentence += trg\n",
    "    return sentence\n",
    "\n",
    "print(vars(train_data.examples[0]))\n",
    "\n",
    "show_complete_example(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SRC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6d663329f776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SRC' is not defined"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-43c0a7204ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TRG' is not defined"
     ]
    }
   ],
   "source": [
    "TRG.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 5879\n",
      "Unique tokens in target (en) vocabulary: 19\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    device=device)\n",
    "\n",
    "auto_train_iterator, auto_valid_iterator, auto_test_iterator = BucketIterator.splits(\n",
    "    (auto_train_data, auto_valid_data, auto_test_data),\n",
    "    batch_size=batch_size,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
    "        self.dense = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.tanh(self.dense(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        \n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "                \n",
    "        #a = [batch size, src len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5879, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (dense): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(19, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=19, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,977,235 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            \n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            \n",
    "            output = model(src, trg, 0)\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede sem pre-treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 38s\n",
      "\tTrain Loss: 0.529 | Train PPL:   1.697\n",
      "\t Val. Loss: 1.151 |  Val. PPL:   3.160\n",
      "Epoch: 02 | Time: 0m 39s\n",
      "\tTrain Loss: 0.371 | Train PPL:   1.450\n",
      "\t Val. Loss: 0.992 |  Val. PPL:   2.697\n",
      "Epoch: 03 | Time: 0m 39s\n",
      "\tTrain Loss: 0.334 | Train PPL:   1.397\n",
      "\t Val. Loss: 0.858 |  Val. PPL:   2.359\n",
      "Epoch: 04 | Time: 0m 39s\n",
      "\tTrain Loss: 0.324 | Train PPL:   1.383\n",
      "\t Val. Loss: 0.705 |  Val. PPL:   2.024\n",
      "Epoch: 05 | Time: 0m 39s\n",
      "\tTrain Loss: 0.321 | Train PPL:   1.379\n",
      "\t Val. Loss: 0.714 |  Val. PPL:   2.043\n",
      "Epoch: 06 | Time: 0m 39s\n",
      "\tTrain Loss: 0.243 | Train PPL:   1.275\n",
      "\t Val. Loss: 0.818 |  Val. PPL:   2.266\n",
      "Epoch: 07 | Time: 0m 39s\n",
      "\tTrain Loss: 0.222 | Train PPL:   1.248\n",
      "\t Val. Loss: 0.318 |  Val. PPL:   1.375\n",
      "Epoch: 08 | Time: 0m 39s\n",
      "\tTrain Loss: 0.171 | Train PPL:   1.186\n",
      "\t Val. Loss: 0.580 |  Val. PPL:   1.786\n",
      "Epoch: 09 | Time: 0m 39s\n",
      "\tTrain Loss: 0.187 | Train PPL:   1.205\n",
      "\t Val. Loss: 0.982 |  Val. PPL:   2.670\n",
      "Epoch: 10 | Time: 0m 39s\n",
      "\tTrain Loss: 0.119 | Train PPL:   1.126\n",
      "\t Val. Loss: 0.965 |  Val. PPL:   2.626\n",
      "Epoch: 11 | Time: 0m 39s\n",
      "\tTrain Loss: 0.136 | Train PPL:   1.146\n",
      "\t Val. Loss: 0.471 |  Val. PPL:   1.602\n",
      "Epoch: 12 | Time: 0m 39s\n",
      "\tTrain Loss: 0.128 | Train PPL:   1.136\n",
      "\t Val. Loss: 0.539 |  Val. PPL:   1.714\n",
      "Epoch: 13 | Time: 0m 39s\n",
      "\tTrain Loss: 0.090 | Train PPL:   1.094\n",
      "\t Val. Loss: 0.867 |  Val. PPL:   2.380\n",
      "Epoch: 14 | Time: 0m 39s\n",
      "\tTrain Loss: 0.111 | Train PPL:   1.117\n",
      "\t Val. Loss: 0.559 |  Val. PPL:   1.749\n",
      "Epoch: 15 | Time: 0m 39s\n",
      "\tTrain Loss: 0.085 | Train PPL:   1.089\n",
      "\t Val. Loss: 0.997 |  Val. PPL:   2.711\n",
      "Epoch: 16 | Time: 0m 39s\n",
      "\tTrain Loss: 0.095 | Train PPL:   1.099\n",
      "\t Val. Loss: 0.677 |  Val. PPL:   1.967\n",
      "Epoch: 17 | Time: 0m 39s\n",
      "\tTrain Loss: 0.085 | Train PPL:   1.089\n",
      "\t Val. Loss: 0.612 |  Val. PPL:   1.844\n",
      "Epoch: 18 | Time: 0m 39s\n",
      "\tTrain Loss: 0.074 | Train PPL:   1.077\n",
      "\t Val. Loss: 0.768 |  Val. PPL:   2.156\n",
      "Epoch: 19 | Time: 0m 39s\n",
      "\tTrain Loss: 0.084 | Train PPL:   1.087\n",
      "\t Val. Loss: 0.223 |  Val. PPL:   1.249\n",
      "Epoch: 20 | Time: 0m 39s\n",
      "\tTrain Loss: 0.062 | Train PPL:   1.064\n",
      "\t Val. Loss: 0.315 |  Val. PPL:   1.370\n"
     ]
    }
   ],
   "source": [
    "filename = '4.1-punctuation-no-pretraining.pt'\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '../models/' + filename)\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.220 | Test PPL:   1.246 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/' + filename))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence  0\n",
      "Original Sentence: <sos> a <unk> brown dog walking on the grass <eos>\n",
      "Sentence  1\n",
      "Original Sentence: <sos> two men sit talking near a stone building <eos>\n",
      "Sentence  2\n",
      "Original Sentence: <sos> the two kids are playing at the playground <eos>\n",
      "Sentence  3\n",
      "Original Sentence: <sos> the boy is outside enjoying a summer day <eos>\n",
      "Sentence  4\n",
      "Original Sentence: <sos> girl wearing radio t shirt has open mouth <eos>\n",
      "Sentence  5\n",
      "Original Sentence: <sos> two men breakdancing with a crowd looking on <eos>\n",
      "Sentence  6\n",
      "Original Sentence: <sos> little girl kicks black object at karate class <eos>\n",
      "Sentence  7\n",
      "Original Sentence: <sos> a kid crosscountry skis wearing the number <unk> <eos>\n",
      "Sentence  8\n",
      "Original Sentence: <sos> a man with graying hair <unk> his beard <eos>\n",
      "Sentence  9\n",
      "Original Sentence: <sos> white duck <unk> its wings in the water <eos>\n",
      "Sentence  10\n",
      "Original Sentence: <sos> the teen jumps the hill with his bicycle <eos>\n",
      "Sentence  11\n",
      "Original Sentence: <sos> the boy jumps onto his soccer player brother <eos>\n",
      "Sentence  12\n",
      "Original Sentence: <sos> young kids are on a small train ride <eos>\n",
      "Sentence  13\n",
      "Original Sentence: <sos> a brown dog runs down the sandy beach <eos>\n",
      "Sentence  14\n",
      "Original Sentence: <sos> an asian factory worker posing for the camera <eos>\n",
      "Sentence  15\n",
      "Original Sentence: <sos> a young man skateboards off a pink railing <eos>\n",
      "Sentence  16\n",
      "Original Sentence: <sos> woman selling bags of fruit on a sidewalk <eos>\n",
      "Sentence  17\n",
      "Original Sentence: <sos> fans cheer as the band plays a song <eos>\n",
      "Sentence  18\n",
      "Original Sentence: <sos> a black boy is sitting in the sand <eos>\n",
      "Sentence  19\n",
      "Original Sentence: <sos> a boy in shorts doing a skateboard trick <eos>\n",
      "Sentence  20\n",
      "Original Sentence: <sos> parked cars with a school bus behind them <eos>\n",
      "Sentence  21\n",
      "Original Sentence: <sos> a chinese man sitting down waiting for customers <eos>\n",
      "Sentence  22\n",
      "Original Sentence: <sos> two brown dogs playing in a rough manner <eos>\n",
      "Sentence  23\n",
      "Original Sentence: <sos> many people are sitting around a tent outside <eos>\n",
      "Sentence  24\n",
      "Original Sentence: <sos> a <unk> relaxes and waits at an airport <eos>\n",
      "Sentence  25\n",
      "Original Sentence: <sos> two workers spread cement onto a brick building <eos>\n",
      "Sentence  26\n",
      "Original Sentence: <sos> people <unk> in at forest next to canoes <eos>\n",
      "Sentence  27\n",
      "Original Sentence: <sos> a black dog <unk> up into a pool <eos>\n",
      "Sentence  28\n",
      "Original Sentence: <sos> a brown and white dog fetching a toy <eos>\n",
      "Sentence  29\n",
      "Original Sentence: <sos> a man using a chainsaw to cut <unk> <eos>\n",
      "Sentence  30\n",
      "Original Sentence: <sos> a dog drinks water outside on the grass <eos>\n",
      "Sentence  31\n",
      "Original Sentence: <sos> two men and a lady are standing outside <eos>\n",
      "Sentence  32\n",
      "Original Sentence: <sos> a dog runs outside with a yellow toy <eos>\n",
      "Sentence  33\n",
      "Original Sentence: <sos> a man wearing an orange shirt and helmet <eos>\n",
      "Sentence  34\n",
      "Original Sentence: <sos> two people riding bikes through a mountainous region <eos>\n",
      "Sentence  35\n",
      "Original Sentence: <sos> a woman is holding a small white statue <eos>\n",
      "Sentence  36\n",
      "Original Sentence: <sos> two brown dogs are running through the snow <eos>\n",
      "Sentence  37\n",
      "Original Sentence: <sos> two young boys putting fruit on the bike <eos>\n",
      "Sentence  38\n",
      "Original Sentence: <sos> guitar player performs at a nightclub red guitar <eos>\n",
      "Sentence  39\n",
      "Original Sentence: <sos> a man is grilling out in his backyard <eos>\n",
      "Sentence  40\n",
      "Original Sentence: <sos> a cheerleading team doing a routine on chairs <eos>\n",
      "Sentence  41\n",
      "Original Sentence: <sos> a large group of people fill a street <eos>\n",
      "Sentence  42\n",
      "Original Sentence: <sos> the young lady is looking at the pizza <eos>\n",
      "Sentence  43\n",
      "Original Sentence: <sos> women wearing traditional clothing are <unk> native life <eos>\n",
      "Sentence  44\n",
      "Original Sentence: <sos> people are fixing the roof of a house <eos>\n",
      "Sentence  45\n",
      "Original Sentence: <sos> two cars are driving on a racetrack <eos> <pad>\n",
      "Sentence  46\n",
      "Original Sentence: <sos> people playing a game in the pool <eos> <pad>\n",
      "Sentence  47\n",
      "Original Sentence: <sos> two boys play soccer against each other <eos> <pad>\n",
      "Sentence  48\n",
      "Original Sentence: <sos> a group of people talking at tables <eos> <pad>\n",
      "Sentence  49\n",
      "Original Sentence: <sos> men play soccer on a muddy field <eos> <pad>\n",
      "Sentence  50\n",
      "Original Sentence: <sos> a girl plays in a small pool <eos> <pad>\n",
      "Sentence  51\n",
      "Original Sentence: <sos> a yellow bulldozer working to move dirt <eos> <pad>\n",
      "Sentence  52\n",
      "Original Sentence: <sos> three men are cooking in a kitchen <eos> <pad>\n",
      "Sentence  53\n",
      "Original Sentence: <sos> the <unk> <unk> water during his <unk> <eos> <pad>\n",
      "Sentence  54\n",
      "Original Sentence: <sos> two children are playing on a bicycle <eos> <pad>\n",
      "Sentence  55\n",
      "Original Sentence: <sos> 3 men cooking in a small kitchen <eos> <pad>\n",
      "Sentence  56\n",
      "Original Sentence: <sos> crowds of people are all riding bicycles <eos> <pad>\n",
      "Sentence  57\n",
      "Original Sentence: <sos> two boys are playing on the sidewalk <eos> <pad>\n",
      "Sentence  58\n",
      "Original Sentence: <sos> three girls are smiling for a picture <eos> <pad>\n",
      "Sentence  59\n",
      "Original Sentence: <sos> people are admiring a work of art <eos> <pad>\n",
      "Sentence  60\n",
      "Original Sentence: <sos> two <unk> are posing for a picture <eos> <pad>\n",
      "Sentence  61\n",
      "Original Sentence: <sos> construction workers <unk> against <unk> construction services <eos> <pad>\n",
      "Sentence  62\n",
      "Original Sentence: <sos> two individual climbing up a steep mountain <eos> <pad>\n",
      "Sentence  63\n",
      "Original Sentence: <sos> some plants are growing near the window <eos> <pad>\n",
      "Sentence  64\n",
      "Original Sentence: <sos> man carrying a few <unk> of beer <eos> <pad>\n",
      "Sentence  65\n",
      "Original Sentence: <sos> a child is on a motorcycle smiling <eos> <pad>\n",
      "Sentence  66\n",
      "Original Sentence: <sos> police officer watching woman exit from bus <eos> <pad>\n",
      "Sentence  67\n",
      "Original Sentence: <sos> a crane operates amidst piles of rubble <eos> <pad>\n",
      "Sentence  68\n",
      "Original Sentence: <sos> man in shorts standing by the water <eos> <pad>\n",
      "Sentence  69\n",
      "Original Sentence: <sos> two guys with <unk> piercings are smiling <eos> <pad>\n",
      "Sentence  70\n",
      "Original Sentence: <sos> two bald drag <unk> in red dresses <eos> <pad>\n",
      "Sentence  71\n",
      "Original Sentence: <sos> a brown dog jumping over a hurdle <eos> <pad>\n",
      "Sentence  72\n",
      "Original Sentence: <sos> hockey player in white uniform with stick <eos> <pad>\n",
      "Sentence  73\n",
      "Original Sentence: <sos> a man standing on a city street <eos> <pad>\n",
      "Sentence  74\n",
      "Original Sentence: <sos> a person is playing an unique instrument <eos> <pad>\n",
      "Sentence  75\n",
      "Original Sentence: <sos> <unk> <unk> are marching with the band <eos> <pad>\n",
      "Sentence  76\n",
      "Original Sentence: <sos> a crowd is present at a bar <eos> <pad>\n",
      "Sentence  77\n",
      "Original Sentence: <sos> three people smiling and holding political signs <eos> <pad>\n",
      "Sentence  78\n",
      "Original Sentence: <sos> two soccer teams are on the field <eos> <pad>\n",
      "Sentence  79\n",
      "Original Sentence: <sos> a man doing a trick on skateboard <eos> <pad>\n",
      "Sentence  80\n",
      "Original Sentence: <sos> an asian man is cooking food outdoors <eos> <pad>\n",
      "Sentence  81\n",
      "Original Sentence: <sos> a blond child swinging on a swing <eos> <pad>\n",
      "Sentence  82\n",
      "Original Sentence: <sos> a small black dog jumping over gates <eos> <pad>\n",
      "Sentence  83\n",
      "Original Sentence: <sos> an asian woman <unk> her hair back <eos> <pad>\n",
      "Sentence  84\n",
      "Original Sentence: <sos> a crowd on a busy daytime street <eos> <pad>\n",
      "Sentence  85\n",
      "Original Sentence: <sos> a light brown dog is running up <eos> <pad>\n",
      "Sentence  86\n",
      "Original Sentence: <sos> a dog jumps over an obstacle outside <eos> <pad>\n",
      "Sentence  87\n",
      "Original Sentence: <sos> a view of a crowded city street <eos> <pad>\n",
      "Sentence  88\n",
      "Original Sentence: <sos> two german <unk> snarling at each other <eos> <pad>\n",
      "Sentence  89\n",
      "Original Sentence: <sos> a little girl opening a christmas present <eos> <pad>\n",
      "Sentence  90\n",
      "Original Sentence: <sos> a <unk> terrier leaps after a ball <eos> <pad>\n",
      "Sentence  91\n",
      "Original Sentence: <sos> man scaling wall with fire in hand <eos> <pad>\n",
      "Sentence  92\n",
      "Original Sentence: <sos> two indian men participating in a ceremony <eos> <pad>\n",
      "Sentence  93\n",
      "Original Sentence: <sos> a man is working a hotdog stand <eos> <pad>\n",
      "Sentence  94\n",
      "Original Sentence: <sos> the boy is wakeboarding on the lake <eos> <pad>\n",
      "Sentence  95\n",
      "Original Sentence: <sos> three teenagers in a subway playing around <eos> <pad>\n",
      "Sentence  96\n",
      "Original Sentence: <sos> a young girl swimming in a pool <eos> <pad>\n",
      "Sentence  97\n",
      "Original Sentence: <sos> two men wearing black in a city <eos> <pad>\n",
      "Sentence  98\n",
      "Original Sentence: <sos> a man cooking food on the stove <eos> <pad>\n",
      "Sentence  99\n",
      "Original Sentence: <sos> a toddler is cooking with another person <eos> <pad>\n",
      "Sentence  100\n",
      "Original Sentence: <sos> a child is splashing in the water <eos> <pad>\n",
      "Sentence  101\n",
      "Original Sentence: <sos> a boy stands with three girls <eos> <pad> <pad>\n",
      "Sentence  102\n",
      "Original Sentence: <sos> doctors performing some type of surgery <eos> <pad> <pad>\n",
      "Sentence  103\n",
      "Original Sentence: <sos> firemen <unk> from a subway station <eos> <pad> <pad>\n",
      "Sentence  104\n",
      "Original Sentence: <sos> two groups of swimmers wade out <eos> <pad> <pad>\n",
      "Sentence  105\n",
      "Original Sentence: <sos> two men sitting in a restaurant <eos> <pad> <pad>\n",
      "Sentence  106\n",
      "Original Sentence: <sos> a rock concert is taking place <eos> <pad> <pad>\n",
      "Sentence  107\n",
      "Original Sentence: <sos> two guys and a girl smiling <eos> <pad> <pad>\n",
      "Sentence  108\n",
      "Original Sentence: <sos> two young children are on sand <eos> <pad> <pad>\n",
      "Sentence  109\n",
      "Original Sentence: <sos> an army officer is inspecting something <eos> <pad> <pad>\n",
      "Sentence  110\n",
      "Original Sentence: <sos> a man is using electronic equipment <eos> <pad> <pad>\n",
      "Sentence  111\n",
      "Original Sentence: <sos> a man on his wedding day <eos> <pad> <pad>\n",
      "Sentence  112\n",
      "Original Sentence: <sos> three construction workers are <unk> pavement <eos> <pad> <pad>\n",
      "Sentence  113\n",
      "Original Sentence: <sos> three men are walking up hill <eos> <pad> <pad>\n",
      "Sentence  114\n",
      "Original Sentence: <sos> dogs run at a dog racetrack <eos> <pad> <pad>\n",
      "Sentence  115\n",
      "Original Sentence: <sos> two dogs play by a tree <eos> <pad> <pad>\n",
      "Sentence  116\n",
      "Original Sentence: <sos> a car parked at the beach <eos> <pad> <pad>\n",
      "Sentence  117\n",
      "Original Sentence: <sos> a pretty woman plays a <unk> <eos> <pad> <pad>\n",
      "Sentence  118\n",
      "Original Sentence: <sos> a man cutting branches of trees <eos> <pad> <pad>\n",
      "Sentence  119\n",
      "Original Sentence: <sos> people standing outside of a building <eos> <pad> <pad>\n",
      "Sentence  120\n",
      "Original Sentence: <sos> three people sit in a cave <eos> <pad> <pad>\n",
      "Sentence  121\n",
      "Original Sentence: <sos> a guy works on a building <eos> <pad> <pad>\n",
      "Sentence  122\n",
      "Original Sentence: <sos> young woman climbing rock face <eos> <pad> <pad> <pad>\n",
      "Sentence  123\n",
      "Original Sentence: <sos> a woman is playing volleyball <eos> <pad> <pad> <pad>\n",
      "Sentence  124\n",
      "Original Sentence: <sos> a deer jumps a fence <eos> <pad> <pad> <pad>\n",
      "Sentence  125\n",
      "Original Sentence: <sos> a biker jumps an obstacle <eos> <pad> <pad> <pad>\n",
      "Sentence  126\n",
      "Original Sentence: <sos> people sit inside a train <eos> <pad> <pad> <pad>\n",
      "Sentence  127\n",
      "Original Sentence: <sos> two men wearing hats <eos> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_sentence(tokens, vocab):\n",
    "    words = list()\n",
    "    for tok in tokens:\n",
    "        words.append(vocab.itos[tok])\n",
    "    return ' '.join(words)\n",
    "\n",
    "test_batch = next(iter(test_iterator))\n",
    "src = test_batch.src\n",
    "trg = test_batch.trg\n",
    "\n",
    "model.eval()\n",
    "output = torch.argmax(model.forward(src, trg, 0), -1)\n",
    "\n",
    "\n",
    "for i, (src, out, tar) in enumerate(zip(src.permute(1, 0), output.permute(1, 0), trg.permute(1, 0))):\n",
    "    print(\"Sentence \", i)\n",
    "    print(\"Original Sentence:\", tokens_to_sentence(src, SRC.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede com pre-treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = None\n",
    "enc = None\n",
    "dec = None\n",
    "\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "#OUTPUT_DIM = len(TRG.vocab)\n",
    "OUTPUT_DIM = INPUT_DIM\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5879, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (dense): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5879, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5879, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=SRC_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 12s\n",
      "\tTrain Loss: 5.034 | Train PPL: 153.513\n",
      "\t Val. Loss: 4.781 |  Val. PPL: 119.236\n",
      "Epoch: 02 | Time: 1m 12s\n",
      "\tTrain Loss: 3.084 | Train PPL:  21.854\n",
      "\t Val. Loss: 1.775 |  Val. PPL:   5.903\n",
      "Epoch: 03 | Time: 1m 11s\n",
      "\tTrain Loss: 1.154 | Train PPL:   3.172\n",
      "\t Val. Loss: 0.813 |  Val. PPL:   2.254\n",
      "Epoch: 04 | Time: 1m 12s\n",
      "\tTrain Loss: 0.545 | Train PPL:   1.725\n",
      "\t Val. Loss: 0.436 |  Val. PPL:   1.547\n",
      "Epoch: 05 | Time: 1m 11s\n",
      "\tTrain Loss: 0.302 | Train PPL:   1.352\n",
      "\t Val. Loss: 0.281 |  Val. PPL:   1.324\n",
      "Epoch: 06 | Time: 1m 12s\n",
      "\tTrain Loss: 0.182 | Train PPL:   1.199\n",
      "\t Val. Loss: 0.205 |  Val. PPL:   1.227\n",
      "Epoch: 07 | Time: 1m 11s\n",
      "\tTrain Loss: 0.107 | Train PPL:   1.113\n",
      "\t Val. Loss: 0.196 |  Val. PPL:   1.217\n",
      "Epoch: 08 | Time: 1m 11s\n",
      "\tTrain Loss: 0.080 | Train PPL:   1.083\n",
      "\t Val. Loss: 0.260 |  Val. PPL:   1.297\n",
      "Epoch: 09 | Time: 1m 12s\n",
      "\tTrain Loss: 0.066 | Train PPL:   1.069\n",
      "\t Val. Loss: 0.189 |  Val. PPL:   1.207\n",
      "Epoch: 10 | Time: 1m 11s\n",
      "\tTrain Loss: 0.064 | Train PPL:   1.066\n",
      "\t Val. Loss: 0.195 |  Val. PPL:   1.215\n",
      "Epoch: 11 | Time: 1m 12s\n",
      "\tTrain Loss: 0.065 | Train PPL:   1.067\n",
      "\t Val. Loss: 0.295 |  Val. PPL:   1.342\n",
      "Epoch: 12 | Time: 1m 11s\n",
      "\tTrain Loss: 0.110 | Train PPL:   1.117\n",
      "\t Val. Loss: 0.126 |  Val. PPL:   1.134\n",
      "Epoch: 13 | Time: 1m 11s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.049\n",
      "\t Val. Loss: 0.105 |  Val. PPL:   1.110\n",
      "Epoch: 14 | Time: 1m 12s\n",
      "\tTrain Loss: 0.029 | Train PPL:   1.030\n",
      "\t Val. Loss: 0.101 |  Val. PPL:   1.106\n",
      "Epoch: 15 | Time: 1m 11s\n",
      "\tTrain Loss: 0.055 | Train PPL:   1.057\n",
      "\t Val. Loss: 0.119 |  Val. PPL:   1.126\n",
      "Epoch: 16 | Time: 1m 12s\n",
      "\tTrain Loss: 0.057 | Train PPL:   1.059\n",
      "\t Val. Loss: 0.105 |  Val. PPL:   1.111\n",
      "Epoch: 17 | Time: 1m 11s\n",
      "\tTrain Loss: 0.055 | Train PPL:   1.057\n",
      "\t Val. Loss: 0.111 |  Val. PPL:   1.117\n",
      "Epoch: 18 | Time: 1m 11s\n",
      "\tTrain Loss: 0.027 | Train PPL:   1.028\n",
      "\t Val. Loss: 0.112 |  Val. PPL:   1.119\n",
      "Epoch: 19 | Time: 1m 12s\n",
      "\tTrain Loss: 0.037 | Train PPL:   1.038\n",
      "\t Val. Loss: 0.124 |  Val. PPL:   1.132\n",
      "Epoch: 20 | Time: 1m 11s\n",
      "\tTrain Loss: 0.026 | Train PPL:   1.026\n",
      "\t Val. Loss: 0.086 |  Val. PPL:   1.090\n"
     ]
    }
   ],
   "source": [
    "filename = '4.1-punctuation-with-pretraining.pt'\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, auto_train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, auto_valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '../models/' + filename)\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = None\n",
    "dec = None\n",
    "\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "#enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5879, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (dense): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(19, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=19, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if not name.startswith('encoder'):\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 39s\n",
      "\tTrain Loss: 0.481 | Train PPL:   1.618\n",
      "\t Val. Loss: 0.824 |  Val. PPL:   2.280\n",
      "Epoch: 02 | Time: 0m 39s\n",
      "\tTrain Loss: 0.385 | Train PPL:   1.469\n",
      "\t Val. Loss: 0.731 |  Val. PPL:   2.076\n",
      "Epoch: 03 | Time: 0m 39s\n",
      "\tTrain Loss: 0.353 | Train PPL:   1.424\n",
      "\t Val. Loss: 0.842 |  Val. PPL:   2.320\n",
      "Epoch: 04 | Time: 0m 39s\n",
      "\tTrain Loss: 0.317 | Train PPL:   1.373\n",
      "\t Val. Loss: 0.403 |  Val. PPL:   1.497\n",
      "Epoch: 05 | Time: 0m 39s\n",
      "\tTrain Loss: 0.302 | Train PPL:   1.353\n",
      "\t Val. Loss: 0.651 |  Val. PPL:   1.917\n",
      "Epoch: 06 | Time: 0m 39s\n",
      "\tTrain Loss: 0.213 | Train PPL:   1.237\n",
      "\t Val. Loss: 0.734 |  Val. PPL:   2.084\n",
      "Epoch: 07 | Time: 0m 39s\n",
      "\tTrain Loss: 0.217 | Train PPL:   1.242\n",
      "\t Val. Loss: 0.566 |  Val. PPL:   1.761\n",
      "Epoch: 08 | Time: 0m 39s\n",
      "\tTrain Loss: 0.161 | Train PPL:   1.175\n",
      "\t Val. Loss: 0.235 |  Val. PPL:   1.264\n",
      "Epoch: 09 | Time: 0m 39s\n",
      "\tTrain Loss: 0.144 | Train PPL:   1.154\n",
      "\t Val. Loss: 0.147 |  Val. PPL:   1.158\n",
      "Epoch: 10 | Time: 0m 39s\n",
      "\tTrain Loss: 0.116 | Train PPL:   1.123\n",
      "\t Val. Loss: 0.121 |  Val. PPL:   1.129\n",
      "Epoch: 11 | Time: 0m 39s\n",
      "\tTrain Loss: 0.102 | Train PPL:   1.107\n",
      "\t Val. Loss: 0.107 |  Val. PPL:   1.113\n",
      "Epoch: 12 | Time: 0m 39s\n",
      "\tTrain Loss: 0.108 | Train PPL:   1.115\n",
      "\t Val. Loss: 0.136 |  Val. PPL:   1.146\n",
      "Epoch: 13 | Time: 0m 39s\n",
      "\tTrain Loss: 0.087 | Train PPL:   1.091\n",
      "\t Val. Loss: 0.167 |  Val. PPL:   1.182\n",
      "Epoch: 14 | Time: 0m 39s\n",
      "\tTrain Loss: 0.097 | Train PPL:   1.102\n",
      "\t Val. Loss: 0.249 |  Val. PPL:   1.283\n",
      "Epoch: 15 | Time: 0m 39s\n",
      "\tTrain Loss: 0.109 | Train PPL:   1.116\n",
      "\t Val. Loss: 0.300 |  Val. PPL:   1.349\n",
      "Epoch: 16 | Time: 0m 39s\n",
      "\tTrain Loss: 0.085 | Train PPL:   1.089\n",
      "\t Val. Loss: 0.164 |  Val. PPL:   1.178\n",
      "Epoch: 17 | Time: 0m 39s\n",
      "\tTrain Loss: 0.072 | Train PPL:   1.075\n",
      "\t Val. Loss: 0.179 |  Val. PPL:   1.196\n",
      "Epoch: 18 | Time: 0m 39s\n",
      "\tTrain Loss: 0.075 | Train PPL:   1.078\n",
      "\t Val. Loss: 0.151 |  Val. PPL:   1.163\n",
      "Epoch: 19 | Time: 0m 39s\n",
      "\tTrain Loss: 0.093 | Train PPL:   1.098\n",
      "\t Val. Loss: 0.192 |  Val. PPL:   1.211\n",
      "Epoch: 20 | Time: 0m 39s\n",
      "\tTrain Loss: 0.060 | Train PPL:   1.062\n",
      "\t Val. Loss: 0.265 |  Val. PPL:   1.303\n"
     ]
    }
   ],
   "source": [
    "filename = '4.1-punctuation-with-pretraining.pt'\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '../models/' + filename)\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.099 | Test PPL:   1.104 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/' + filename))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence  0\n",
      "Original Sentence: <sos> a <unk> brown dog walking on the grass <eos>\n",
      "Sentence  1\n",
      "Original Sentence: <sos> two men sit talking near a stone building <eos>\n",
      "Sentence  2\n",
      "Original Sentence: <sos> the two kids are playing at the playground <eos>\n",
      "Sentence  3\n",
      "Original Sentence: <sos> the boy is outside enjoying a summer day <eos>\n",
      "Sentence  4\n",
      "Original Sentence: <sos> girl wearing radio t shirt has open mouth <eos>\n",
      "Sentence  5\n",
      "Original Sentence: <sos> two men breakdancing with a crowd looking on <eos>\n",
      "Sentence  6\n",
      "Original Sentence: <sos> little girl kicks black object at karate class <eos>\n",
      "Sentence  7\n",
      "Original Sentence: <sos> a kid crosscountry skis wearing the number <unk> <eos>\n",
      "Sentence  8\n",
      "Original Sentence: <sos> a man with graying hair <unk> his beard <eos>\n",
      "Sentence  9\n",
      "Original Sentence: <sos> white duck <unk> its wings in the water <eos>\n",
      "Sentence  10\n",
      "Original Sentence: <sos> the teen jumps the hill with his bicycle <eos>\n",
      "Sentence  11\n",
      "Original Sentence: <sos> the boy jumps onto his soccer player brother <eos>\n",
      "Sentence  12\n",
      "Original Sentence: <sos> young kids are on a small train ride <eos>\n",
      "Sentence  13\n",
      "Original Sentence: <sos> a brown dog runs down the sandy beach <eos>\n",
      "Sentence  14\n",
      "Original Sentence: <sos> an asian factory worker posing for the camera <eos>\n",
      "Sentence  15\n",
      "Original Sentence: <sos> a young man skateboards off a pink railing <eos>\n",
      "Sentence  16\n",
      "Original Sentence: <sos> woman selling bags of fruit on a sidewalk <eos>\n",
      "Sentence  17\n",
      "Original Sentence: <sos> fans cheer as the band plays a song <eos>\n",
      "Sentence  18\n",
      "Original Sentence: <sos> a black boy is sitting in the sand <eos>\n",
      "Sentence  19\n",
      "Original Sentence: <sos> a boy in shorts doing a skateboard trick <eos>\n",
      "Sentence  20\n",
      "Original Sentence: <sos> parked cars with a school bus behind them <eos>\n",
      "Sentence  21\n",
      "Original Sentence: <sos> a chinese man sitting down waiting for customers <eos>\n",
      "Sentence  22\n",
      "Original Sentence: <sos> two brown dogs playing in a rough manner <eos>\n",
      "Sentence  23\n",
      "Original Sentence: <sos> many people are sitting around a tent outside <eos>\n",
      "Sentence  24\n",
      "Original Sentence: <sos> a <unk> relaxes and waits at an airport <eos>\n",
      "Sentence  25\n",
      "Original Sentence: <sos> two workers spread cement onto a brick building <eos>\n",
      "Sentence  26\n",
      "Original Sentence: <sos> people <unk> in at forest next to canoes <eos>\n",
      "Sentence  27\n",
      "Original Sentence: <sos> a black dog <unk> up into a pool <eos>\n",
      "Sentence  28\n",
      "Original Sentence: <sos> a brown and white dog fetching a toy <eos>\n",
      "Sentence  29\n",
      "Original Sentence: <sos> a man using a chainsaw to cut <unk> <eos>\n",
      "Sentence  30\n",
      "Original Sentence: <sos> a dog drinks water outside on the grass <eos>\n",
      "Sentence  31\n",
      "Original Sentence: <sos> two men and a lady are standing outside <eos>\n",
      "Sentence  32\n",
      "Original Sentence: <sos> a dog runs outside with a yellow toy <eos>\n",
      "Sentence  33\n",
      "Original Sentence: <sos> a man wearing an orange shirt and helmet <eos>\n",
      "Sentence  34\n",
      "Original Sentence: <sos> two people riding bikes through a mountainous region <eos>\n",
      "Sentence  35\n",
      "Original Sentence: <sos> a woman is holding a small white statue <eos>\n",
      "Sentence  36\n",
      "Original Sentence: <sos> two brown dogs are running through the snow <eos>\n",
      "Sentence  37\n",
      "Original Sentence: <sos> two young boys putting fruit on the bike <eos>\n",
      "Sentence  38\n",
      "Original Sentence: <sos> guitar player performs at a nightclub red guitar <eos>\n",
      "Sentence  39\n",
      "Original Sentence: <sos> a man is grilling out in his backyard <eos>\n",
      "Sentence  40\n",
      "Original Sentence: <sos> a cheerleading team doing a routine on chairs <eos>\n",
      "Sentence  41\n",
      "Original Sentence: <sos> a large group of people fill a street <eos>\n",
      "Sentence  42\n",
      "Original Sentence: <sos> the young lady is looking at the pizza <eos>\n",
      "Sentence  43\n",
      "Original Sentence: <sos> women wearing traditional clothing are <unk> native life <eos>\n",
      "Sentence  44\n",
      "Original Sentence: <sos> people are fixing the roof of a house <eos>\n",
      "Sentence  45\n",
      "Original Sentence: <sos> two cars are driving on a racetrack <eos> <pad>\n",
      "Sentence  46\n",
      "Original Sentence: <sos> people playing a game in the pool <eos> <pad>\n",
      "Sentence  47\n",
      "Original Sentence: <sos> two boys play soccer against each other <eos> <pad>\n",
      "Sentence  48\n",
      "Original Sentence: <sos> a group of people talking at tables <eos> <pad>\n",
      "Sentence  49\n",
      "Original Sentence: <sos> men play soccer on a muddy field <eos> <pad>\n",
      "Sentence  50\n",
      "Original Sentence: <sos> a girl plays in a small pool <eos> <pad>\n",
      "Sentence  51\n",
      "Original Sentence: <sos> a yellow bulldozer working to move dirt <eos> <pad>\n",
      "Sentence  52\n",
      "Original Sentence: <sos> three men are cooking in a kitchen <eos> <pad>\n",
      "Sentence  53\n",
      "Original Sentence: <sos> the <unk> <unk> water during his <unk> <eos> <pad>\n",
      "Sentence  54\n",
      "Original Sentence: <sos> two children are playing on a bicycle <eos> <pad>\n",
      "Sentence  55\n",
      "Original Sentence: <sos> 3 men cooking in a small kitchen <eos> <pad>\n",
      "Sentence  56\n",
      "Original Sentence: <sos> crowds of people are all riding bicycles <eos> <pad>\n",
      "Sentence  57\n",
      "Original Sentence: <sos> two boys are playing on the sidewalk <eos> <pad>\n",
      "Sentence  58\n",
      "Original Sentence: <sos> three girls are smiling for a picture <eos> <pad>\n",
      "Sentence  59\n",
      "Original Sentence: <sos> people are admiring a work of art <eos> <pad>\n",
      "Sentence  60\n",
      "Original Sentence: <sos> two <unk> are posing for a picture <eos> <pad>\n",
      "Sentence  61\n",
      "Original Sentence: <sos> construction workers <unk> against <unk> construction services <eos> <pad>\n",
      "Sentence  62\n",
      "Original Sentence: <sos> two individual climbing up a steep mountain <eos> <pad>\n",
      "Sentence  63\n",
      "Original Sentence: <sos> some plants are growing near the window <eos> <pad>\n",
      "Sentence  64\n",
      "Original Sentence: <sos> man carrying a few <unk> of beer <eos> <pad>\n",
      "Sentence  65\n",
      "Original Sentence: <sos> a child is on a motorcycle smiling <eos> <pad>\n",
      "Sentence  66\n",
      "Original Sentence: <sos> police officer watching woman exit from bus <eos> <pad>\n",
      "Sentence  67\n",
      "Original Sentence: <sos> a crane operates amidst piles of rubble <eos> <pad>\n",
      "Sentence  68\n",
      "Original Sentence: <sos> man in shorts standing by the water <eos> <pad>\n",
      "Sentence  69\n",
      "Original Sentence: <sos> two guys with <unk> piercings are smiling <eos> <pad>\n",
      "Sentence  70\n",
      "Original Sentence: <sos> two bald drag <unk> in red dresses <eos> <pad>\n",
      "Sentence  71\n",
      "Original Sentence: <sos> a brown dog jumping over a hurdle <eos> <pad>\n",
      "Sentence  72\n",
      "Original Sentence: <sos> hockey player in white uniform with stick <eos> <pad>\n",
      "Sentence  73\n",
      "Original Sentence: <sos> a man standing on a city street <eos> <pad>\n",
      "Sentence  74\n",
      "Original Sentence: <sos> a person is playing an unique instrument <eos> <pad>\n",
      "Sentence  75\n",
      "Original Sentence: <sos> <unk> <unk> are marching with the band <eos> <pad>\n",
      "Sentence  76\n",
      "Original Sentence: <sos> a crowd is present at a bar <eos> <pad>\n",
      "Sentence  77\n",
      "Original Sentence: <sos> three people smiling and holding political signs <eos> <pad>\n",
      "Sentence  78\n",
      "Original Sentence: <sos> two soccer teams are on the field <eos> <pad>\n",
      "Sentence  79\n",
      "Original Sentence: <sos> a man doing a trick on skateboard <eos> <pad>\n",
      "Sentence  80\n",
      "Original Sentence: <sos> an asian man is cooking food outdoors <eos> <pad>\n",
      "Sentence  81\n",
      "Original Sentence: <sos> a blond child swinging on a swing <eos> <pad>\n",
      "Sentence  82\n",
      "Original Sentence: <sos> a small black dog jumping over gates <eos> <pad>\n",
      "Sentence  83\n",
      "Original Sentence: <sos> an asian woman <unk> her hair back <eos> <pad>\n",
      "Sentence  84\n",
      "Original Sentence: <sos> a crowd on a busy daytime street <eos> <pad>\n",
      "Sentence  85\n",
      "Original Sentence: <sos> a light brown dog is running up <eos> <pad>\n",
      "Sentence  86\n",
      "Original Sentence: <sos> a dog jumps over an obstacle outside <eos> <pad>\n",
      "Sentence  87\n",
      "Original Sentence: <sos> a view of a crowded city street <eos> <pad>\n",
      "Sentence  88\n",
      "Original Sentence: <sos> two german <unk> snarling at each other <eos> <pad>\n",
      "Sentence  89\n",
      "Original Sentence: <sos> a little girl opening a christmas present <eos> <pad>\n",
      "Sentence  90\n",
      "Original Sentence: <sos> a <unk> terrier leaps after a ball <eos> <pad>\n",
      "Sentence  91\n",
      "Original Sentence: <sos> man scaling wall with fire in hand <eos> <pad>\n",
      "Sentence  92\n",
      "Original Sentence: <sos> two indian men participating in a ceremony <eos> <pad>\n",
      "Sentence  93\n",
      "Original Sentence: <sos> a man is working a hotdog stand <eos> <pad>\n",
      "Sentence  94\n",
      "Original Sentence: <sos> the boy is wakeboarding on the lake <eos> <pad>\n",
      "Sentence  95\n",
      "Original Sentence: <sos> three teenagers in a subway playing around <eos> <pad>\n",
      "Sentence  96\n",
      "Original Sentence: <sos> a young girl swimming in a pool <eos> <pad>\n",
      "Sentence  97\n",
      "Original Sentence: <sos> two men wearing black in a city <eos> <pad>\n",
      "Sentence  98\n",
      "Original Sentence: <sos> a man cooking food on the stove <eos> <pad>\n",
      "Sentence  99\n",
      "Original Sentence: <sos> a toddler is cooking with another person <eos> <pad>\n",
      "Sentence  100\n",
      "Original Sentence: <sos> a child is splashing in the water <eos> <pad>\n",
      "Sentence  101\n",
      "Original Sentence: <sos> a boy stands with three girls <eos> <pad> <pad>\n",
      "Sentence  102\n",
      "Original Sentence: <sos> doctors performing some type of surgery <eos> <pad> <pad>\n",
      "Sentence  103\n",
      "Original Sentence: <sos> firemen <unk> from a subway station <eos> <pad> <pad>\n",
      "Sentence  104\n",
      "Original Sentence: <sos> two groups of swimmers wade out <eos> <pad> <pad>\n",
      "Sentence  105\n",
      "Original Sentence: <sos> two men sitting in a restaurant <eos> <pad> <pad>\n",
      "Sentence  106\n",
      "Original Sentence: <sos> a rock concert is taking place <eos> <pad> <pad>\n",
      "Sentence  107\n",
      "Original Sentence: <sos> two guys and a girl smiling <eos> <pad> <pad>\n",
      "Sentence  108\n",
      "Original Sentence: <sos> two young children are on sand <eos> <pad> <pad>\n",
      "Sentence  109\n",
      "Original Sentence: <sos> an army officer is inspecting something <eos> <pad> <pad>\n",
      "Sentence  110\n",
      "Original Sentence: <sos> a man is using electronic equipment <eos> <pad> <pad>\n",
      "Sentence  111\n",
      "Original Sentence: <sos> a man on his wedding day <eos> <pad> <pad>\n",
      "Sentence  112\n",
      "Original Sentence: <sos> three construction workers are <unk> pavement <eos> <pad> <pad>\n",
      "Sentence  113\n",
      "Original Sentence: <sos> three men are walking up hill <eos> <pad> <pad>\n",
      "Sentence  114\n",
      "Original Sentence: <sos> dogs run at a dog racetrack <eos> <pad> <pad>\n",
      "Sentence  115\n",
      "Original Sentence: <sos> two dogs play by a tree <eos> <pad> <pad>\n",
      "Sentence  116\n",
      "Original Sentence: <sos> a car parked at the beach <eos> <pad> <pad>\n",
      "Sentence  117\n",
      "Original Sentence: <sos> a pretty woman plays a <unk> <eos> <pad> <pad>\n",
      "Sentence  118\n",
      "Original Sentence: <sos> a man cutting branches of trees <eos> <pad> <pad>\n",
      "Sentence  119\n",
      "Original Sentence: <sos> people standing outside of a building <eos> <pad> <pad>\n",
      "Sentence  120\n",
      "Original Sentence: <sos> three people sit in a cave <eos> <pad> <pad>\n",
      "Sentence  121\n",
      "Original Sentence: <sos> a guy works on a building <eos> <pad> <pad>\n",
      "Sentence  122\n",
      "Original Sentence: <sos> young woman climbing rock face <eos> <pad> <pad> <pad>\n",
      "Sentence  123\n",
      "Original Sentence: <sos> a woman is playing volleyball <eos> <pad> <pad> <pad>\n",
      "Sentence  124\n",
      "Original Sentence: <sos> a deer jumps a fence <eos> <pad> <pad> <pad>\n",
      "Sentence  125\n",
      "Original Sentence: <sos> a biker jumps an obstacle <eos> <pad> <pad> <pad>\n",
      "Sentence  126\n",
      "Original Sentence: <sos> people sit inside a train <eos> <pad> <pad> <pad>\n",
      "Sentence  127\n",
      "Original Sentence: <sos> two men wearing hats <eos> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_sentence(tokens, vocab):\n",
    "    words = list()\n",
    "    for tok in tokens:\n",
    "        words.append(vocab.itos[tok])\n",
    "    return ' '.join(words)\n",
    "\n",
    "test_batch = next(iter(test_iterator))\n",
    "src = test_batch.src\n",
    "trg = test_batch.trg\n",
    "\n",
    "model.eval()\n",
    "output = torch.argmax(model.forward(src, trg, 0), -1)\n",
    "\n",
    "\n",
    "for i, (src, out, tar) in enumerate(zip(src.permute(1, 0), output.permute(1, 0), trg.permute(1, 0))):\n",
    "    print(\"Sentence \", i)\n",
    "    print(\"Original Sentence:\", tokens_to_sentence(src, SRC.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
