{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\\n\", \"The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\\\/director Peter Jackson 's expanded vision of J.R.R. Tolkien 's Middle-earth .\\n\", 'Effective but too-tepid biopic\\n', 'If you sometimes like to go to the movies to have fun , Wasabi is a good place to start .\\n', \"Emerges as something rare , an issue movie that 's so honest and keenly observed that it does n't feel like one .\\n\", 'The film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\\n', 'Offers that rare combination of entertainment and education .\\n', 'Perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\\n', \"Steers turns in a snappy screenplay that curls at the edges ; it 's so clever you want to hate it .\\n\", 'But he somehow pulls it off .\\n']\n",
      "['1', '1', '2', '2', '2', '2', '2', '2', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from os.path import join\n",
    "\n",
    "data_folder = Path('../../data/STT2/')\n",
    "\n",
    "sentences_file = Path('sentences.txt')\n",
    "sentences_path = join(data_folder, sentences_file)\n",
    "\n",
    "sentences = open(sentences_path).readlines()[1:]\n",
    "sentences = list(map(lambda x: x.strip(), sentences))\n",
    "sentences = list(map(lambda x: x.split('\\t')[1], sentences))\n",
    "sentences = list(map(lambda x: x + '\\n', sentences))\n",
    "\n",
    "splits_file = Path('split.txt')\n",
    "splits_path = join(data_folder, splits_file)\n",
    "\n",
    "splits = open(splits_path).readlines()[1:]\n",
    "splits = list(map(lambda x: x.strip(), splits))\n",
    "splits = list(map(lambda x: x.split(',')[1], splits))\n",
    "\n",
    "print(sentences[:10])\n",
    "print(splits[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "sentence_split = defaultdict(list)\n",
    "for sentence, split in zip(sentences, splits):\n",
    "    sentence_split[split].append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação dos exemplos\n",
    "* 1 - Train\n",
    "* 2 - Test\n",
    "* 3 - Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = Path(\"train.txt\")\n",
    "test_file = Path(\"test.txt\")\n",
    "dev_file = Path(\"dev.txt\")\n",
    "\n",
    "for idx, file in enumerate([train_file, test_file, dev_file]):\n",
    "    \n",
    "    path = join(data_folder, file)\n",
    "    with open(path, 'w') as f:\n",
    "        f.writelines(sentence_split[str(idx + 1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
